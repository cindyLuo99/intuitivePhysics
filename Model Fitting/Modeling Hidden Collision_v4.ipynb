{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48b8aea",
   "metadata": {},
   "source": [
    "# Find the position of the obstacle x_predict, y_predict for each condition (72 in total)\n",
    "# Update: adding varying x into modeling. Previous: fixed x but varying y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc92759",
   "metadata": {},
   "source": [
    "# (1) Pure Linear Projection\n",
    "\n",
    "A **scatter plot of path projection predictions vs. human collider placements**, as a baseline to compare a more sophisticated model that uses intuitive physics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea51108",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9d5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import binned_statistic_2d\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from matplotlib.cm import hsv\n",
    "from shapely.geometry import Point, LineString\n",
    "import pybrms\n",
    "from similaritymeasures import frechet_dist\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal\n",
    "import pickle\n",
    "import subprocess\n",
    "from scipy.optimize import minimize, Bounds\n",
    "from pathlib import Path\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "canvasWidth = 1000 \n",
    "canvasHeight = 600\n",
    "ball_Xs = [322.3, 322.3, 322.3, 322.3, 500 , 500 , 500 , 500 , 604.4, 604.4, 604.4, 604.4]\n",
    "color_map = plt.get_cmap('viridis', 6)\n",
    "green = color_map(4)\n",
    "modeling_choice = 'Model_both_x_and_y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49268d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for different elements\n",
    "ground_truth_color = 'cyan'\n",
    "model_prediction_color = 'darkblue'\n",
    "# human_centroid_color = 'gray'\n",
    "human_centroid_color = '#0A704E'\n",
    "participant_color = green \n",
    "# participant_color = 'blueviolet'\n",
    "screen_color = 'lightgray'\n",
    "ball_color = '#ececd1'\n",
    "# anchor_color = '#f59f01'\n",
    "# anchor_color = '#0A704E' # dark_green\n",
    "anchor_color = 'darkviolet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509ed35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the string in a dataframe to list when loading csv\n",
    "def string2List(dataString):\n",
    "    dataList = ast.literal_eval(dataString)\n",
    "    return dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd13b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the summed log likelihoods, sample size, and the number of free parameters, calculate BIC\n",
    "# sample size should be the number of observations/the number of data points\n",
    "def getBIC(k, sampleSize, sumLogLike):\n",
    "    result = k*np.log(sampleSize) - 2*sumLogLike\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5103dc",
   "metadata": {},
   "source": [
    "## Add fd_metric to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecdb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# canvas settings\n",
    "segmented_line = [((250, 150), (250, 450)), ((250, 450), (750, 450)), ((750, 450), (750, 150))]\n",
    "top_y = 150\n",
    "bottom_y = 450\n",
    "left_x = 150\n",
    "right_x = 750\n",
    "ball_radius = 30\n",
    "obstacle_radius = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6739e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all points that are outside of the screen\n",
    "# return list1, list2\n",
    "# list1: list of points that form the path before the ball enters the screen (when ball_y <= top_y + ball_radius)\n",
    "# list2: list of points that form the path before the ball exits the screen (when ball_y >= bottom_y - ball_radius or ball_x <= left_x + ball_radius or ball_x >= right_x - ball_radius)\n",
    "def pickPointsOutScreen(path, top_y, bottom_y, left_x, right_x, ball_radius, keepSpeed = False):\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    if len(path[0])==3:\n",
    "        for ball_x,ball_y,speed in path:\n",
    "            if ball_y <= top_y + ball_radius:\n",
    "                if keepSpeed:\n",
    "                    list1.append((ball_x,ball_y,speed))\n",
    "                else:\n",
    "                    list1.append((ball_x,ball_y))\n",
    "            if (ball_y >= bottom_y - ball_radius) or (ball_x <= left_x + ball_radius) or (ball_x >= right_x - ball_radius):\n",
    "                if keepSpeed:\n",
    "                    list2.append((ball_x,ball_y,speed))\n",
    "                else:\n",
    "                    list2.append((ball_x,ball_y))\n",
    "    else: \n",
    "        for ball_x,ball_y in path:\n",
    "            if ball_y <= top_y + ball_radius:\n",
    "                list1.append((ball_x,ball_y))\n",
    "            if (ball_y >= bottom_y - ball_radius) or (ball_x <= left_x + ball_radius) or (ball_x >= right_x - ball_radius):\n",
    "                list2.append((ball_x,ball_y))\n",
    "    return list1, list2\n",
    "\n",
    "# calculate Fréchet distance between list1_participant and list1_groundTruth (fd1) and list2_participant and list2_groundTruth (fd2)\n",
    "# return fd1, fd2\n",
    "def evaluateResponseByFD(rowData):\n",
    "    simulatedPath = rowData['simulated_path']\n",
    "    exactPath = rowData['exact_path_single']\n",
    "    l1_p, l2_p = pickPointsOutScreen(simulatedPath, top_y, bottom_y, left_x, right_x, ball_radius)\n",
    "    l1_g, l2_g = pickPointsOutScreen(exactPath, top_y, bottom_y, left_x, right_x, ball_radius)\n",
    "    fd1 = frechet_dist(l1_p, l1_g)\n",
    "    fd2 = frechet_dist(l2_p, l2_g)\n",
    "    return fd1, fd2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b2624",
   "metadata": {},
   "source": [
    "## Load Full Data Stored from Previous Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510dc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dataframe contains the ground truth trajectories of the ball, simulated trajectory of each participant's response, as well as the fd1, fd2 evaluated \n",
    "allData = pd.read_csv('df_all_with_single_ground_trajectory_simulation_fd_pilot_v1.csv')\n",
    "allData['exact_path_single'] = allData['exact_path_single'].apply(string2List)\n",
    "allData['simulated_path'] = allData['simulated_path'].apply(string2List)\n",
    "allData['fd_combined'] = allData['fd1_enter'] + allData['fd2_exit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f533938",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Visualizing the fd_combined by conditions\n",
    "\n",
    "# Create a boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='stimulus_idx', y='fd_combined', data=allData, width = 0.5, flierprops={\"marker\": \"o\", \"markersize\": 3},showmeans=True,  \n",
    "            meanprops={'marker':'o',\n",
    "                       'markerfacecolor':'white', \n",
    "                       'markeredgecolor':'black',\n",
    "                       'markersize':'5'},\n",
    "            hue='stimulus_idx',  # Assign the 'x' variable also to 'hue'\n",
    "            palette='Set2',  # Use a qualitative color palette\n",
    "            legend=False) \n",
    "\n",
    "# Add a horizontal line at y=0\n",
    "plt.axhline(y=0, color='gray', linestyle='--')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Similarity')\n",
    "# plt.title('Distribution of Fréchet Distances Across Conditions')\n",
    "\n",
    "# Show the plot\n",
    "# plt.savefig('fd_12_conditions.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69efa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of the fd performances\n",
    "allData['fd_combined'].mean() # 77.746"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a9d0b",
   "metadata": {},
   "source": [
    "## Get Linear Projection Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d0acb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_line = [((250, 150), (250, 450)), ((250, 450), (750, 450)), ((750, 450), (750, 150))]\n",
    "\n",
    "# Create a function that find the two consecutive coordinates of the ball when it is about to fall outside of the screen\n",
    "def distance_to_segment(point, segment):\n",
    "    \"\"\"Calculate the distance from a point to a line segment.\"\"\"\n",
    "    return Point(point).distance(LineString(segment))\n",
    "\n",
    "def closest_points_to_line(points, segmented_line = segmented_line):\n",
    "    \"\"\"Find two points that are nearest to the segmented line and are also near each other.\"\"\"\n",
    "    # Calculate distances from all points to the segmented line\n",
    "    distances = [min(distance_to_segment(point, segment) for segment in segmented_line) for point in points]\n",
    "    \n",
    "    # Sort points based on their distance to the segmented line\n",
    "    sorted_points = sorted(points, key=lambda p: min(distance_to_segment(p, segment) for segment in segmented_line))\n",
    "    \n",
    "    for point in sorted_points:\n",
    "        # Sort other points based on their distance to the current point\n",
    "        other_points = sorted(points, key=lambda p: np.linalg.norm(np.array(point) - np.array(p)))\n",
    "        for near_point in other_points[1:3]:  # considering the 2 nearest points\n",
    "            if abs(distances[points.index(point)] - distances[points.index(near_point)]) < 5:\n",
    "                return point, near_point\n",
    "    return None\n",
    "\n",
    "# Function to get the first two elements of each tuple\n",
    "def take_first_two(lst):\n",
    "    return [(a, b) for a, b, _ in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9976c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the no speed path col\n",
    "allData['exact_path_no_speed'] = allData['exact_path_single'].apply(take_first_two)\n",
    "\n",
    "# create the vertical line col\n",
    "allData['projected_line_0'] = allData['ball_X']\n",
    "\n",
    "# create the tangential line col\n",
    "allData['projected_line_1'] = allData['exact_path_no_speed'].apply(closest_points_to_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa149423",
   "metadata": {},
   "source": [
    "## save allData to pickle to skip some of the data preparation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca68bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a Pickle file\n",
    "# allData.to_pickle('allData_Sep_29.pkl')\n",
    "\n",
    "# Load it back without needing string2List\n",
    "allData = pd.read_pickle('allData_Sep_29.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f1ce5a",
   "metadata": {},
   "source": [
    "### check by visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27ad994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawProjectedPath(condition, merged_trajectory, ax, zorder):\n",
    "    # Given data\n",
    "    subset = merged_trajectory[merged_trajectory['stimulus_idx']==condition]\n",
    "    x_vertical = subset['projected_line_0'].iloc[0]\n",
    "    point1 = subset['projected_line_1'].iloc[0][0]\n",
    "    point2 = subset['projected_line_1'].iloc[0][1]\n",
    "    \n",
    "    # Calculate slope\n",
    "    if (point2[0] - point1[0]) == 0:\n",
    "        slope = float('inf')\n",
    "    else:\n",
    "        slope = (point2[1] - point1[1]) / (point2[0] - point1[0])\n",
    "        \n",
    "        \n",
    "    # Calculate extended points based on the slope\n",
    "    x_extended_1 = 100  # at the far left of the plot\n",
    "    y_extended_1 = point1[1] + slope * (x_extended_1 - point1[0])\n",
    "\n",
    "    x_extended_2 = 900  # at the far right of the plot\n",
    "    y_extended_2 = point1[1] + slope * (x_extended_2 - point1[0])\n",
    "    \n",
    "    # Create the two line segments\n",
    "    vertical_line = LineString([(x_vertical, -200), (x_vertical, 600)])  # assuming a large y range for the vertical line\n",
    "    extended_line = LineString([(x_extended_1, y_extended_1), (x_extended_2, y_extended_2)])\n",
    "    \n",
    "    # Calculate intersection\n",
    "    intersection = vertical_line.intersection(extended_line)\n",
    "    print(f'stimulus:{condition}')\n",
    "    print(intersection)\n",
    "\n",
    "    # Plotting\n",
    "    if intersection and 100 <= intersection.x <= 900 and 60 <= intersection.y <= 540:\n",
    "        ax.plot([x_vertical, x_vertical], [0, intersection.y], label=\"Vertical Line\", linestyle='--', color='black', zorder = zorder) \n",
    "        if intersection.y <= y_extended_1:\n",
    "            ax.plot([x_extended_1, intersection.x], [y_extended_1, intersection.y], label=\"Extended Line\", linestyle='--', color='black', zorder = zorder)\n",
    "        else:\n",
    "            ax.plot([intersection.x, x_extended_2], [intersection.y, y_extended_2], label=\"Extended Line\", linestyle='--', color='black', zorder = zorder)\n",
    "#         ax.scatter(*intersection.xy, color='yellow', label=\"Intersection\", s = 100, zorder = 20)\n",
    "    else:\n",
    "        ax.plot([x_vertical, x_vertical], [0, 600], label=\"Vertical Line\", linestyle='--', color='black', zorder = zorder)  # using a large y range for visualization\n",
    "        ax.plot([x_extended_1, x_extended_2], [y_extended_1, y_extended_2], label=\"Extended Line\", linestyle='--', color='black', zorder = zorder)\n",
    "#         ax.scatter(*intersection.xy, color='yellow', label=\"Intersection\", s = 100, zorder = 20)\n",
    "    return intersection\n",
    "\n",
    "def drawTrueTrajectory(condition, df, ax, zorder):\n",
    "    subset = df[df['stimulus_idx'] == condition]\n",
    "    trails = subset['exact_path_single']\n",
    "    data_list = subset['exact_path_single'].iloc[0]\n",
    "    x_coords = [item[0] for item in data_list]\n",
    "    y_coords = [item[1] for item in data_list]\n",
    "    ax.plot(x_coords, y_coords, '-', color='cyan', linewidth=2, zorder=zorder)\n",
    "#     ax.scatter(x_coords, y_coords, c='cyan', s=4, zorder = zorder)\n",
    "    \n",
    "def drawSimulatedTrajectory(condition, trajectoryName, df, ax, zorder):\n",
    "    subset = df[df['stimulus_idx'] == condition]\n",
    "    trails = subset[trajectoryName]\n",
    "    data_list = subset[trajectoryName].iloc[0]\n",
    "    x_coords = [item[0] for item in data_list]\n",
    "    y_coords = [item[1] for item in data_list]\n",
    "    ax.scatter(x_coords, y_coords, c='red', s=2, zorder = zorder)\n",
    "    \n",
    "def drawHumanCentroid(condition, obstacle, humanCentroidJSON, ax, alpha, zorder):\n",
    "    with open(humanCentroidJSON, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    df_simulated = pd.json_normalize(data)\n",
    "    \n",
    "    trajectory = df_simulated.loc[(df_simulated['stimulus_idx'] == condition) & (df_simulated['obstacle_idx'] == obstacle), 'simulated_trial'].iloc[0]\n",
    "    x_coords = [item[0] for item in trajectory]\n",
    "    y_coords = [item[1] for item in trajectory]\n",
    "    \n",
    "#     ax.scatter(x_coords, y_coords, c='gray', s=4, alpha = alpha, zorder = zorder)\n",
    "    \n",
    "    # placement of the triangle\n",
    "    x_triangle = df_simulated.loc[(df_simulated['stimulus_idx'] == condition) & (df_simulated['obstacle_idx'] == obstacle), 'obstacle_X'].iloc[0]\n",
    "    y_triangle = df_simulated.loc[(df_simulated['stimulus_idx'] == condition) & (df_simulated['obstacle_idx'] == obstacle), 'obstacle_Y'].iloc[0]\n",
    "#     print(x_triangle, y_triangle)\n",
    "    return x_triangle, y_triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fddff8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = allData # to be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0e24f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersections = {}\n",
    "conditions = np.sort(df_all['obstacle_idx'].unique())\n",
    "\n",
    "# Define a color map for your conditions\n",
    "color_map = {1: 'red', 2: 'red', 3: '#757575', 4: '#757575', 5: '#0088DE', 6: '#0088DE'}\n",
    "\n",
    "# Reshape positions into a 3x4 array and flatten by column\n",
    "positions = np.sort(df_all['stimulus_idx'].unique())\n",
    "positions = positions.reshape((3, 4)).T.flatten()\n",
    "\n",
    "fig, axs = plt.subplots(4, 3, figsize=(28, 24)) # Creates a 4x3 grid of Axes objects\n",
    "\n",
    "# Empty lists to hold all handles and labels\n",
    "handles, labels = [], []\n",
    "\n",
    "for index, position in enumerate(positions):\n",
    "    ax = axs.flatten()[index]  # Select the current Axes object\n",
    "\n",
    "    # Draw triangle and rectangle\n",
    "    x_coord = df_all.loc[df_all['stimulus_idx'] == position, 'obstacle_groundTruth_x'].values[0]\n",
    "    y_coord = df_all.loc[df_all['stimulus_idx'] == position, 'obstacle_groundTruth_y'].values[0]\n",
    "    x_coord_ball = df_all.loc[df_all['stimulus_idx'] == position, 'ball_X'].values[0]\n",
    "    y_coord_ball = 100\n",
    "    print(x_coord, y_coord)\n",
    "    ball = patches.Circle((x_coord_ball, y_coord_ball), radius = 30, color = '#ececd1')\n",
    "    triangle = patches.RegularPolygon((x_coord,y_coord), orientation=np.pi, numVertices=3, radius=45, color='#5fa55a', fill=True)\n",
    "    rect = patches.Rectangle((250,150),500,300,linewidth=1, edgecolor='lightgray',facecolor='lightgray')\n",
    "    ax.add_patch(ball)\n",
    "    ax.add_patch(rect)\n",
    "    ax.add_patch(triangle)\n",
    "    \n",
    "    for i, condition in enumerate(conditions):\n",
    "        subset = df_all[(df_all['stimulus_idx'] == position) & (df_all['obstacle_idx'] == condition)]\n",
    "        ax.scatter(subset[\"triangle_final_x_flipback\"], subset[\"triangle_final_y\"], s=20, color=color_map[i+1], alpha = 0.6)\n",
    "        \n",
    "        # Plot initial positions\n",
    "        initial_x = subset['obstacle_initial_x'].unique()\n",
    "        initial_y = subset['obstacle_initial_y'].unique()\n",
    "        ax.scatter(initial_x, initial_y, marker='x', color='white',linewidth=5, s=130, zorder=10)  \n",
    "        scatter = ax.scatter(initial_x, initial_y, marker='x', color=color_map[i+1],linewidth=3, s=100, zorder=10)  \n",
    "\n",
    "        # Add handles and labels to lists\n",
    "        if len(handles) < len(conditions):\n",
    "            handles.append(scatter)\n",
    "            labels.append(f'Initial position: {int(condition)}')\n",
    "    \n",
    "    # plot the true trajectory\n",
    "    drawTrueTrajectory(position, df_all, ax, 7)\n",
    "    \n",
    "    # plot the simulated trajectory of the participants' centroids (12 in total)\n",
    "#     drawSimulatedTrajectory(position, 'simulated_trial', df_simulated, ax, 7)\n",
    "#     drawSimulatedTrajectory(position, 'simulated_trial', df, ax, 7)\n",
    "    \n",
    "    # plot the projected path\n",
    "    intersection = drawProjectedPath(position, df_all, ax, 7)\n",
    "    intersections[position] = [intersection.x, intersection.y]\n",
    "    \n",
    "    ax.set_xlim(100, 900)\n",
    "    ax.set_ylim(60, 540)\n",
    "    ax.invert_yaxis() # invert the y-axis\n",
    "    ax.set_xlabel(\"triangle_final_x\")\n",
    "    ax.set_title(f'Pos {int(position)}')\n",
    "    \n",
    "plt.tight_layout()  \n",
    "# add color bar\n",
    "# cax = fig.add_axes([1.05, 0.2, 0.02, 0.6])  # Adjust the position and size as needed\n",
    "# cb = ColorbarBase(cax, cmap=hsv, orientation='vertical', norm=plt.Normalize(vmin=global_min, vmax=global_max))\n",
    "# cb.set_label('Speed Value')\n",
    "\n",
    "fig.legend(handles, labels, loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b28460",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88445a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the intersections\n",
    "# assume that participants always assume that the ball bounces off the midpoint of the triangle's sides\n",
    "d = (30 + (45/2))/2*(3**0.5) # 45.46633369868302\n",
    "fall_Direction = {1.0: 'left', 2.0: 'right', 3.0: 'right', 4.0: 'left', \n",
    "                 5.0: 'right', 6.0: 'right', 7.0: 'left', 8.0: 'left',\n",
    "                 9.0: 'left', 10.0: 'right', 11.0: 'left', 12.0: 'right'}\n",
    "intersections_modified = {}\n",
    "for key in intersections:\n",
    "    direction = fall_Direction[key]\n",
    "    if direction == 'left':\n",
    "        intersections_modified[key] = [intersections[key][0] + d, intersections[key][1]]\n",
    "    else:\n",
    "        intersections_modified[key] = [intersections[key][0] - d, intersections[key][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af6d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ea4d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections_modified_by_anchor = {}\n",
    "for i in intersections_modified.keys():\n",
    "    for j in range(1,7):\n",
    "        new_key = (i,j)\n",
    "        intersections_modified_by_anchor[new_key] = intersections_modified[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9096d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections_modified_by_anchor # LP intersections by anchor, 72 intersections (condition, obstacle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0622616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotComparison(x_human, y_human, x_model, y_model, std_dev_human_x, std_dev_human_y, label, std_dev_model_x = None, std_dev_model_y = None):\n",
    "    # Creating the plots with error bars\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot for X comparisons\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.errorbar(x_model, x_human, xerr=std_dev_model_x, yerr=std_dev_human_x, fmt='o', color='blue', ecolor='lightgray', label='X Comparisons')\n",
    "    xlim = plt.xlim()\n",
    "    ylim = plt.ylim()\n",
    "    line_range = [min(xlim[0], ylim[0]), max(xlim[1], ylim[1])]\n",
    "    plt.plot(line_range, line_range, 'k--')\n",
    "    plt.xlabel(f'{label} X', fontsize=16)\n",
    "    plt.ylabel('Human X Responses', fontsize=16)\n",
    "    plt.xlim(line_range)\n",
    "    plt.ylim(line_range)\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot for Y comparisons\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.errorbar(y_model, y_human, xerr=std_dev_model_y, yerr=std_dev_human_y, fmt='o', color='green', ecolor='lightgray', label='Y Comparisons')\n",
    "    xlim = plt.xlim()\n",
    "    ylim = plt.ylim()\n",
    "    line_range = [min(xlim[0], ylim[0]), max(xlim[1], ylim[1])]\n",
    "    plt.plot(line_range, line_range, 'k--')\n",
    "    plt.xlabel(f'{label} Y', fontsize=16)\n",
    "    plt.ylabel('Human Y Responses', fontsize=16)\n",
    "    plt.xlim(line_range)\n",
    "    plt.ylim(line_range)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(f'{label} vs. Human Predictions.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd5611",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain data\n",
    "x_human = df_all.groupby(['stimulus_idx','obstacle_idx'])['triangle_final_x_flipback'].mean().values # automatically sorted by 1, 2, 3, ...\n",
    "y_human = df_all.groupby(['stimulus_idx','obstacle_idx'])['triangle_final_y'].mean().values\n",
    "x_model = df_all.groupby(['stimulus_idx','obstacle_idx'])['obstacle_groundTruth_x'].first().values\n",
    "y_model = df_all.groupby(['stimulus_idx','obstacle_idx'])['obstacle_groundTruth_y'].first().values\n",
    "\n",
    "# Assuming some standard deviations for model and human predictions\n",
    "std_dev_human_x = df_all.groupby(['stimulus_idx','obstacle_idx'])['triangle_final_x_flipback'].std().values\n",
    "std_dev_human_y = df_all.groupby(['stimulus_idx','obstacle_idx'])['triangle_final_y'].std().values\n",
    "\n",
    "# Plot comparison between human responses and ground-truth positions (separated by x/y)\n",
    "plotComparison(x_human, y_human, x_model, y_model, std_dev_human_x, std_dev_human_y, 'Ground-truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16701fe7",
   "metadata": {},
   "source": [
    "#### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c56ef2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotComparison_fd(human_fd, model_fd, std_dev_human_fd, label, std_dev_model_fd = None):\n",
    "    # Creating the plots with error bars\n",
    "    plt.figure(figsize=(5, 5))\n",
    "\n",
    "    plt.errorbar(model_fd, human_fd, xerr=std_dev_model_fd, yerr=std_dev_human_fd, fmt='o', color='blue', ecolor='lightgray')\n",
    "\n",
    "    xlim = plt.xlim()\n",
    "    ylim = plt.ylim()\n",
    "    line_range = [min(xlim[0], ylim[0]), max(xlim[1], ylim[1])]\n",
    "    plt.plot(line_range, line_range, 'k--')\n",
    "    plt.xlabel(f'{label} Evaluated by Fréchet Distance', fontsize=15)\n",
    "    plt.ylabel('Human Evaluated by Fréchet Distance', fontsize=15)\n",
    "    plt.xlim(line_range)\n",
    "    plt.ylim(line_range)\n",
    "    \n",
    "    correlation_fd, p_value_fd = pearsonr(human_fd, model_fd)\n",
    "#     print(model_fd)\n",
    "    print(\"p-value:\", p_value_fd)\n",
    "    print(\"Pearson Correlation:\", correlation_fd)\n",
    "    \n",
    "    plt.title(f'Pearson Correlation: {correlation_fd:.3f}', fontsize=15)\n",
    "    plt.savefig(f'Figs_Update_3/{label} vs. Human Predictions_FD.pdf')\n",
    "    plt.show()\n",
    "    return correlation_fd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab6c17",
   "metadata": {},
   "source": [
    "## 2D comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1adbbd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_likelihood(cov_params, all_data, all_means):\n",
    "    \"\"\"\n",
    "    Calculate the total log likelihood for all conditions.\n",
    "    \"\"\"\n",
    "    # Reconstruct the covariance matrix from the parameters\n",
    "    L = np.array([[cov_params[0], 0], [cov_params[1], cov_params[2]]])\n",
    "    cov = L @ L.T\n",
    "\n",
    "    total_likelihood = 0\n",
    "#     count = 0\n",
    "    for data, mean in zip(all_data, all_means):\n",
    "        total_likelihood -= np.sum(multivariate_normal.logpdf(data, mean=mean, cov=cov)) # use log(ab)=log(a)+log(b), so just summing loglikelihoods instead of logsumexp\n",
    "    return total_likelihood\n",
    "\n",
    "def find_single_best_covariance(all_data, all_means, method):\n",
    "    # Initial guess for covariance matrix parameters\n",
    "    initial_cov_params = [10, 0, 10]\n",
    "    \n",
    "    # Ensuring that the diagonal elements are positive & covariance = 0\n",
    "    bounds = Bounds([0, 0, 0], [np.inf, 0, np.inf])\n",
    "\n",
    "    # Run optimization to find the best covariance matrix\n",
    "    result = minimize(calculate_total_likelihood, initial_cov_params, args=(all_data, all_means), bounds=bounds, method = method)\n",
    "\n",
    "    # Reconstruct the optimized covariance matrix\n",
    "#     print(result)\n",
    "    L_optimized = np.array([[result.x[0], 0], [result.x[1], result.x[2]]])\n",
    "    optimized_cov = L_optimized @ L_optimized.T\n",
    "    \n",
    "    # result.fun is the minimized negative log likelihood, so we take the negative to get the log likelihood\n",
    "    return optimized_cov, -result.fun\n",
    "\n",
    "# Example usage\n",
    "# Aggregate data and means for all conditions\n",
    "# Assuming you have a list of data arrays and corresponding means for each condition\n",
    "# Example:\n",
    "# all_data = [data_condition1, data_condition2, ..., data_conditionN]\n",
    "# all_means = [mean_condition1, mean_condition2, ..., mean_conditionN]\n",
    "\n",
    "# optimized_covariance = find_best_covariance(all_data, all_means)\n",
    "# print(optimized_covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ce05f",
   "metadata": {},
   "source": [
    "#### if single covariance matrix that maximizes the sum of the maximum likelihoods calculated per condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66438af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.sort(df_all['stimulus_idx'].unique())\n",
    "anchors = np.sort(df_all['obstacle_idx'].unique())\n",
    "\n",
    "def getBICFromPrediction(x_model, y_model, df_all, k):\n",
    "    positions = np.sort(df_all['stimulus_idx'].unique())\n",
    "    anchors = np.sort(df_all['obstacle_idx'].unique())\n",
    "\n",
    "    # Aggregate data from all conditions, all anchors\n",
    "    all_data = np.array([df_all[(df_all['stimulus_idx'] == pos) & (df_all['obstacle_idx'] == anc)][['triangle_final_x_flipback', 'triangle_final_y']].values for pos in positions for anc in anchors])\n",
    "    # print(len(all_data))\n",
    "\n",
    "    # Mean models for all conditions\n",
    "    all_mean_models = np.array([x_model, y_model]).T\n",
    "    # print(all_mean_models)\n",
    "\n",
    "    # Find a single best-fit covariance matrix for all conditions\n",
    "    optimized_covariance, mle_all = find_single_best_covariance(all_data, all_mean_models, 'Powell')\n",
    "    # optimized_covariance, mle_all = find_single_best_covariance(all_data, all_mean_models, None)\n",
    "    \n",
    "    # Ensure mle_all is a scalar\n",
    "    assert np.isscalar(mle_all), \"mle_all should be a scalar value.\"\n",
    "\n",
    "    print(f\"Best sum log-likelihood: {mle_all}\")\n",
    "    print(f'Best covariance: {optimized_covariance}')\n",
    "    print(f'BIC: {getBIC(k, 1440, mle_all)}')\n",
    "    return mle_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d9f0ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that calculates the fd between ground-truth trajectory and the simulated trajectory of model prediction (stored in jsonFilePath)\n",
    "def compareFD_model_human(jsonFilePath, df_all, label):\n",
    "    with open(jsonFilePath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Convert JSON data to DataFrame and sort it\n",
    "    df_simulated = pd.json_normalize(data)\n",
    "    df_simulated = df_simulated.sort_values(by=['stimulus_idx', 'obstacle_idx']).reset_index(drop=True)\n",
    "    \n",
    "    # Obtain and sort the ground-truth paths\n",
    "    truePaths = df_all.groupby(['stimulus_idx','obstacle_idx'])['exact_path_single'].agg('first').reset_index()\n",
    "    truePaths = truePaths.sort_values(by=['stimulus_idx', 'obstacle_idx']).reset_index(drop=True)\n",
    "    \n",
    "    # Merge simulated data with true paths correctly using an inner join to ensure alignment\n",
    "    df_merge_simulation_truePaths = pd.merge(df_simulated, truePaths, on=['stimulus_idx', 'obstacle_idx'], how='inner')\n",
    "    df_merge_simulation_truePaths = df_merge_simulation_truePaths.rename(columns={\"simulated_trial\": \"simulated_path\"})\n",
    "    \n",
    "    evals_fd = df_merge_simulation_truePaths.apply(evaluateResponseByFD, axis=1)\n",
    "    evals_df = evals_fd.apply(pd.Series)\n",
    "    evals_df.columns = ['fd1_enter', 'fd2_exit']\n",
    "    evals_df['fd_combined'] = evals_df['fd1_enter'] + evals_df['fd2_exit']\n",
    "\n",
    "    df_merge_simulation_truePaths = pd.concat([df_merge_simulation_truePaths, evals_df], axis=1)\n",
    "    \n",
    "    # Calculate the means and standard deviations for human and model FD\n",
    "    human_fd = df_all.groupby(['stimulus_idx', 'obstacle_idx'])['fd_combined'].mean().sort_index().values\n",
    "    model_fd = df_merge_simulation_truePaths['fd_combined'].values\n",
    "\n",
    "    std_dev_human_fd = df_all.groupby(['stimulus_idx', 'obstacle_idx'])['fd_combined'].std().sort_index().values\n",
    "\n",
    "    corr_fd = plotComparison_fd(human_fd, model_fd, std_dev_human_fd, label)\n",
    "\n",
    "    return corr_fd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a8b6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeXYPrediction(x_model, y_model, modelName):\n",
    "    if len(x_model) != 72 or len(y_model) != 72:\n",
    "        print('CHECK Model Predictions. Length != 72.')\n",
    "        if len(x_model) == 12 and len(y_model) == 12:\n",
    "            x_model = [x_sol for x_sol in x_model for _ in range(6)]\n",
    "            y_model = [y_sol for y_sol in y_model for _ in range(6)]\n",
    "    model_dir = Path(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}')\n",
    "    if os.path.exists(f'{model_dir}/x_coords_{modelName}.pkl') and os.path.exists(f'{model_dir}/y_coords_{modelName}.pkl'):\n",
    "        print('Model Predictions Stored Already!')\n",
    "    else:\n",
    "        \n",
    "        model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        with open(f'{model_dir}/x_coords_{modelName}.pkl', 'wb') as f:\n",
    "            pickle.dump(x_model, f)\n",
    "        with open(f'{model_dir}/y_coords_{modelName}.pkl', 'wb') as f:\n",
    "            pickle.dump(y_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95b318",
   "metadata": {},
   "source": [
    "## Code for visualizing the simulated path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab505a",
   "metadata": {},
   "source": [
    "### Get 72 human centroids & Run simulations & analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f645b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 72 human centroids (from participant)\n",
    "x_human = []\n",
    "y_human = []\n",
    "\n",
    "for stimulus_idx in positions:\n",
    "    for obstacle_idx in anchors:\n",
    "        subset = df_all[(df_all['stimulus_idx'] == stimulus_idx) & (df_all['obstacle_idx'] == obstacle_idx)]\n",
    "        x_mean = subset['triangle_final_x_flipback'].mean()\n",
    "        y_mean = subset['triangle_final_y'].mean()\n",
    "#         print(x_mean, y_mean)\n",
    "        x_human.append(x_mean)\n",
    "        y_human.append(y_mean)\n",
    "\n",
    "# storeXYPrediction(x_human, y_human, 'Human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be321498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runScript_72Simulations('runSimulation/full72Trajectories/run72Simulations.py', 'Human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e64a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize72Trials(f'runSimulation/full72Trajectories/Human/all72_results.json', df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d5400",
   "metadata": {},
   "outputs": [],
   "source": [
    "compareFD_model_human(f'runSimulation/full72Trajectories/Human/all72_results.json', df_all, 'Human_Centroid')\n",
    "# if we compare the trajectories of the human centroids with the average fd achieved by the participants in each condition\n",
    "# the correlation is pretty low\n",
    "# this suggests that fitting the centroid (which explains placement positions) vs. fitting the response quality are two different goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de26b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawInitialSetUp(ax, df_all, stimulus_idx, obstacle_idx):\n",
    "    # Draw background rectangle as the screen\n",
    "    screen = patches.Rectangle((250,150), 500, 300, linewidth=1, edgecolor=screen_color, facecolor=screen_color)\n",
    "    ax.add_patch(screen)\n",
    "\n",
    "    # Add the ball using the specific x-coordinate from the data\n",
    "    ball = patches.Circle((ball_Xs[stimulus_idx-1], 100), radius=30, color=ball_color)\n",
    "    ax.add_patch(ball)\n",
    "\n",
    "    # Add the ground truth triangle position\n",
    "    x_coord = df_all.loc[df_all['stimulus_idx'] == stimulus_idx, 'obstacle_groundTruth_x'].values[0]\n",
    "    y_coord = df_all.loc[df_all['stimulus_idx'] == stimulus_idx, 'obstacle_groundTruth_y'].values[0]\n",
    "    triangle = patches.RegularPolygon((x_coord, y_coord), numVertices=3, radius=45, orientation=np.pi, color=ground_truth_color, fill=True)\n",
    "    ax.add_patch(triangle)\n",
    "\n",
    "    # Add the anchor position # orange\n",
    "    subset = df_all[(df_all['stimulus_idx'] == stimulus_idx) & (df_all['obstacle_idx'] == obstacle_idx)]\n",
    "    initial_x = subset['obstacle_initial_x'].unique()\n",
    "    initial_y = subset['obstacle_initial_y'].unique()\n",
    "    ax.scatter(initial_x, initial_y, marker='x', color=anchor_color,linewidth=3, s=60,zorder=8) \n",
    "    \n",
    "    # Plot true trajectory # cyan\n",
    "    drawTrueTrajectory(stimulus_idx, df_all, ax, 5)\n",
    "    \n",
    "    # Plot human centroid trajectory & obstacle # dark gray\n",
    "    human_X, human_Y = drawHumanCentroid(stimulus_idx, obstacle_idx, 'runSimulation/full72Trajectories/Human/all72_results.json', ax, 0.5, 4)\n",
    "    human_avg_response = patches.RegularPolygon((human_X, human_Y), numVertices=3, radius=45, orientation=np.pi, color=human_centroid_color, fill=True, alpha=0.3)\n",
    "    ax.add_patch(human_avg_response)\n",
    "\n",
    "    # Plot Participants Solutions\n",
    "    for path in subset['simulated_path']:\n",
    "        path = np.array(path)  # Make sure it's a numpy array for indexing\n",
    "        ax.plot(path[:, 0], path[:, 1], '-', color=participant_color, linewidth=2, zorder=5, alpha=0.5)\n",
    "\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfee4ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new function with legend\n",
    "def visualize72Trials(jsonFilePath, df_all):\n",
    "    # Load JSON data, containing simulated trajectories from model prediction\n",
    "    with open(jsonFilePath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Convert data to DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "\n",
    "    # Create a 12x6 grid of plots with shared axes and constrained layout\n",
    "    fig, axes = plt.subplots(nrows=12, ncols=6, figsize=(30, 40), sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "    # Loop through each row in the dataframe\n",
    "    for idx, row in df.iterrows():\n",
    "        stimulus_idx = row['stimulus_idx'] - 1  # 0-based index for matplotlib\n",
    "        obstacle_idx = row['obstacle_idx'] - 1  # 0-based index\n",
    "\n",
    "        ax = axes[stimulus_idx, obstacle_idx]\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "        subset = drawInitialSetUp(ax, df_all, row['stimulus_idx'], row['obstacle_idx'])\n",
    "\n",
    "        # Add the model predicted obstacle position\n",
    "        obstacle = patches.RegularPolygon((row['obstacle_X'], row['obstacle_Y']), numVertices=3, radius=45, orientation=np.pi, color=model_prediction_color, fill=True, alpha=0.5)\n",
    "        ax.add_patch(obstacle)\n",
    "\n",
    "        # Plot trajectory\n",
    "        x_coords = [point[0] for point in row['simulated_trial']]\n",
    "        y_coords = [point[1] for point in row['simulated_trial']]\n",
    "        ax.plot(x_coords, y_coords, '-', linewidth=1.5, color='darkblue', label='Trajectory', zorder=6)\n",
    "\n",
    "        ax.set_xlim(100, 900)\n",
    "        ax.set_ylim(60, 540)\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_title(f'Stimulus {row[\"stimulus_idx\"]}, Obstacle {row[\"obstacle_idx\"]}')\n",
    "\n",
    "    # Add a single global legend\n",
    "    handles = [\n",
    "        patches.Patch(color=ground_truth_color, label='Ground Truth'),\n",
    "        patches.Patch(color=model_prediction_color, label='Model Prediction'),\n",
    "        patches.Patch(color=participant_color, label='Participant Trajectories'),\n",
    "        patches.Patch(color=human_centroid_color, label='Human Centroid'),\n",
    "#         patches.Patch(color=ball_color, label='Ball'),\n",
    "#         patches.Patch(color=screen_color, label='Screen'),\n",
    "        patches.Patch(color=anchor_color, label='Anchor Position')\n",
    "    ]\n",
    "    fig.legend(handles=handles, loc='upper center', bbox_to_anchor=(0.5, 1.01), ncol=5, fontsize='16')\n",
    "\n",
    "    fig.supxlabel('X Coordinate', fontsize=16)\n",
    "    fig.supylabel('Y Coordinate', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# This code assumes you have the jsonFilePath and df_all prepared\n",
    "# visualize72Trials('path_to_your_data.json', df_all_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f848bd9",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f2d4a",
   "metadata": {},
   "source": [
    "### Blue Region\n",
    "\n",
    "X (based on falling direction)\n",
    "(x_ball - l, x_ball)  OR\n",
    "(x_ball, x_ball + l)\n",
    "\n",
    "l = r_ball + \\sqrt{3}/2*r_obstacle\n",
    "\n",
    "Y: (150, 450) (occluder top/bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71c356ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# width of the blue region\n",
    "l = ball_radius + 3**0.5/2*obstacle_radius\n",
    "\n",
    "# x_range for stimulus_idx in positions for obstacle_idx in anchors\n",
    "x_blue_range = {}\n",
    "\n",
    "for stimulus_idx in positions:\n",
    "    for obstacle_idx in anchors:\n",
    "        direction = fall_Direction[stimulus_idx]\n",
    "        x_ball = intersections[stimulus_idx][0]\n",
    "        # To make sure the edges of the blue region are exclusive (also to ensure valid collision), \n",
    "        # a tiny margin of 1 is applied. E.g. (150, 350) -> [149, 349].\n",
    "        margin = 1\n",
    "        # if the ball is falling towards the left\n",
    "        # x_min = x_ball + adjustment\n",
    "        # x_max = x_ball + l - adjustment, (otherwise, when x = x_ball + l, no collision would happen)\n",
    "        if direction == 'left':\n",
    "            range_vals = (x_ball + margin, x_ball + l - margin)\n",
    "        else:\n",
    "            range_vals = (x_ball - l + margin, x_ball - margin)\n",
    "            \n",
    "        x_blue_range[stimulus_idx, obstacle_idx] = range_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe74b0a1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_blue_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad33d07",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12090301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runScript_72Simulations(script_path, modelName):\n",
    "    if not os.path.exists(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/all72_results.json'):\n",
    "        try:\n",
    "            print(f\"Running script for: {modelName}\")\n",
    "            result = subprocess.run(\n",
    "                ['python', script_path, modelName],\n",
    "                text=True,  # Ensures outputs are returned as strings\n",
    "                capture_output=True  # Captures output and errors\n",
    "            )\n",
    "            print(f\"Output for {modelName}:\\n{result.stdout}\")\n",
    "            if result.stderr:\n",
    "                print(f\"Errors for {modelName}:\\n{result.stderr}\")\n",
    "            print(f\"Completed script for: {modelName}\")\n",
    "\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"An error occurred while running script for {modelName}: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"Results for model {modelName} already exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c63575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# y_model is randomly drawn between 151, 449\n",
    "# x_model is randomly drawn between x_blue_range\n",
    "\n",
    "MLL_list = []\n",
    "corr_list = []\n",
    "for i in range(30):\n",
    "    x_model = [np.random.uniform(x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for stimulus_idx in positions for obstacle_idx in anchors]\n",
    "    y_model = np.random.uniform(150 + margin, 450 - margin, 72)\n",
    "    modelName = f'random_{i}'\n",
    "    # store x,y coords\n",
    "    storeXYPrediction(x_model, y_model, modelName)\n",
    "    \n",
    "    # get maximum likelihoods\n",
    "    MLL = getBICFromPrediction(x_model, y_model, df_all, 2)\n",
    "    MLL_list.append(MLL)\n",
    "    \n",
    "    # run 72 simulations, if not yet run\n",
    "#     if not os.path.exists(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/all72_results.json'):\n",
    "    runScript_72Simulations(f'runSimulation/full72Trajectories/{modeling_choice}/run72Simulations.py', modelName)\n",
    "    \n",
    "    # calculate correlations\n",
    "    corr = compareFD_model_human(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/all72_results.json', df_all, 'Init$_{Random}$')\n",
    "    corr_list.append(corr)\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "# logsumexp considers the sum of exponentiated log-likelihoods, \n",
    "# which corresponds to combining probabilities before returning to log-space\n",
    "adjusted_logsumexp = logsumexp(MLL_list) - np.log(len(MLL_list))\n",
    "getBIC(2, 1440, adjusted_logsumexp) # 31531.8525 # corrected Sep_29: 31220.487927639057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07586586",
   "metadata": {},
   "outputs": [],
   "source": [
    "getBIC(2, 1440, adjusted_logsumexp) # 31220.487927639057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaed324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average mll across the 30 samples\n",
    "adjusted_logsumexp # -15602.971565426958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461e5fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(corr_list) # 0.2816672581685109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42455108",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize72Trials(f'runSimulation/full72Trajectories/{modeling_choice}/random_14/all72_results.json',df_all) # random_9,14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe82c21",
   "metadata": {},
   "source": [
    "## Linear Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cc864d",
   "metadata": {},
   "source": [
    "### # issue: when modeling x at the same time, the x coordinate determined by LP was x_ball. However, set x_model to be x_ball might result in invalid collision (50/50 falling into either side)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e9673",
   "metadata": {},
   "source": [
    "## LP_approach 1: make x random? Since LP could only fix y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# y_model is set to be LP positions\n",
    "# x_model is randomly drawn between x_blue_range\n",
    "\n",
    "MLL_list_LP = []\n",
    "corr_list_LP = []\n",
    "for i in range(30):\n",
    "    x_model = [np.random.uniform(x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for stimulus_idx in positions for obstacle_idx in anchors]\n",
    "    y_model = y_model = [intersections_modified_by_anchor[(stimulus_idx,obstacle_idx)][1] for stimulus_idx in positions for obstacle_idx in anchors]\n",
    "    modelName = f'LP_xRandom_{i}'\n",
    "    # store x,y coords\n",
    "    storeXYPrediction(x_model, y_model, modelName)\n",
    "    \n",
    "    # get maximum likelihoods\n",
    "    MLL = getBICFromPrediction(x_model, y_model, df_all, 2)\n",
    "    MLL_list_LP.append(MLL)\n",
    "    \n",
    "    # run 72 simulations, if not yet run\n",
    "    runScript_72Simulations(f'runSimulation/full72Trajectories/{modeling_choice}/run72Simulations.py', modelName)\n",
    "    \n",
    "    # calculate correlations\n",
    "    corr = compareFD_model_human(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/all72_results.json', df_all, 'Init$_{LP_xRandom}$')\n",
    "    corr_list_LP.append(corr)\n",
    "\n",
    "getBIC(2, 1440, np.mean(MLL_list_LP)) # 32774.084016321496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(corr_list_LP)) # 0.5027082569370811\n",
    "print(np.mean(MLL_list_LP)) # -16379.769609768176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a1411",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize72Trials(f'runSimulation/full72Trajectories/{modeling_choice}/LP_xRandom_29/all72_results.json',df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc16b2c",
   "metadata": {},
   "source": [
    "## approach 2 : fix x as the previous approach, assume collision midpoint, adjusted by l_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e3d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'Linear_Projection'\n",
    "x_model = [intersections_modified_by_anchor[(stimulus_idx,obstacle_idx)][0] for stimulus_idx in positions for obstacle_idx in anchors] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "# x_model = [np.random.uniform(x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for stimulus_idx in positions for obstacle_idx in anchors]\n",
    "y_model = [intersections_modified_by_anchor[(stimulus_idx,obstacle_idx)][1] for stimulus_idx in positions for obstacle_idx in anchors]\n",
    "\n",
    "storeXYPrediction(x_model, y_model, modelName)\n",
    "\n",
    "getBICFromPrediction(x_model, y_model, df_all, 2)\n",
    "\n",
    "# Best sum log-likelihood: -16258.582836180341\n",
    "# Best covariance: [[  892.56781217     0.        ]\n",
    "#  [    0.         24623.67209481]]\n",
    "# BIC: 32531.710469145823\n",
    "\n",
    "runScript_72Simulations(f'runSimulation/full72Trajectories/{modeling_choice}/run72Simulations.py', modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ab799",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compareFD_model_human(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/all72_results.json', df_all, 'Init$_{LP}$')\n",
    "# p-value: 4.664381787366499e-07\n",
    "# Pearson Correlation: 0.5532128025051875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize72Trials(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/all72_results.json',df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feb2b2c",
   "metadata": {},
   "source": [
    "## approach 3: The point in the blue region that is nearest to the intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49971c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'LP_near'\n",
    "x_model = [nearest_value_in_range(intersections[stimulus_idx][0],x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for stimulus_idx in positions for obstacle_idx in anchors] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_model = [nearest_value_in_range(intersections[stimulus_idx][1], 150 + margin, 450 - margin) for stimulus_idx in positions for obstacle_idx in anchors]\n",
    "\n",
    "storeXYPrediction(x_model, y_model, modelName)\n",
    "\n",
    "getBICFromPrediction(x_model, y_model, df_all, 2)\n",
    "\n",
    "# Best sum log-likelihood: -16180.560490561125\n",
    "# Best covariance: [[ 1528.13625303     0.        ]\n",
    "#  [    0.         12906.43108133]]\n",
    "# BIC: 32375.66577790739\n",
    "\n",
    "\n",
    "runScript_72Simulations(f'runSimulation/full72Trajectories/{modeling_choice}/run72Simulations.py', modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d741e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compareFD_model_human(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/all72_results.json', df_all, 'Init$_{LP_{near}}$')\n",
    "# p-value: 3.678311654244363e-05\n",
    "# Pearson Correlation: 0.4661510063296203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe0ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize72Trials(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/all72_results.json',df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0af117",
   "metadata": {},
   "source": [
    "## Anchor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cdb7f1",
   "metadata": {},
   "source": [
    "## even anchor could help with fixing some of the x_position, it sometimes will still return x_ball. However, can not return the exact ball location, since will cause invalid collision\n",
    "\n",
    "Solution: set a length 1 margin for the blue region, so that a valid collision will always happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c04bb52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_value_in_range(x, range_start, range_end):\n",
    "    if x < range_start:\n",
    "        return range_start\n",
    "    elif x > range_end:\n",
    "        return range_end\n",
    "    else:\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec7098",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.sort(df_all['stimulus_idx'].unique())\n",
    "anchors = np.sort(df_all['obstacle_idx'].unique())\n",
    "anchor_Xs = df_all.groupby(['stimulus_idx','obstacle_idx'])['obstacle_initial_x'].first()\n",
    "\n",
    "modelName = 'Anchor'\n",
    "x_model = [nearest_value_in_range(anchor_Xs[stimulus_idx][obstacle_idx],x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for stimulus_idx in positions for obstacle_idx in anchors] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_model = df_all.groupby(['stimulus_idx','obstacle_idx'])['obstacle_initial_y'].first().values\n",
    "\n",
    "storeXYPrediction(x_model, y_model, modelName)\n",
    "\n",
    "getBICFromPrediction(x_model, y_model, df_all, 2)\n",
    "\n",
    "# Best sum log-likelihood: -15555.833691892942\n",
    "# Best covariance: [[1672.2231159     0.        ]\n",
    "#  [   0.         4952.72557391]]\n",
    "# BIC: 31126.212180571023\n",
    "    \n",
    "runScript_72Simulations(f'runSimulation/full72Trajectories/{modeling_choice}/run72Simulations.py', modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compareFD_model_human(f'runSimulation/full72Trajectories/{modeling_choice}/Anchor/all72_results.json', df_all, 'Init$_{Anchor}$')\n",
    "# p-value: 1.3602436172697692e-06\n",
    "# Pearson Correlation: 0.5340025642116222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf40892",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize72Trials(f'runSimulation/full72Trajectories/{modeling_choice}/Anchor/all72_results.json',df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e99cb69",
   "metadata": {},
   "source": [
    "## Midline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed826d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'Midline'\n",
    "x_model = [nearest_value_in_range(canvasWidth/2, x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for stimulus_idx in positions for obstacle_idx in anchors] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_model = [nearest_value_in_range(canvasHeight/2, 150 + margin, 450 - margin) for stimulus_idx in positions for obstacle_idx in anchors]\n",
    "\n",
    "storeXYPrediction(x_model, y_model, modelName)\n",
    "\n",
    "getBICFromPrediction(x_model, y_model, df_all, 2)\n",
    "# Best sum log-likelihood: -15098.924627238646\n",
    "# Best covariance: [[1714.38214377    0.        ]\n",
    "#  [   0.         2561.01649376]]\n",
    "# BIC: 30212.394051262432\n",
    "runScript_72Simulations(f'runSimulation/full72Trajectories/{modeling_choice}/run72Simulations.py', modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cee676",
   "metadata": {},
   "outputs": [],
   "source": [
    "compareFD_model_human(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/all72_results.json', df_all, 'Init$_{Mid}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4729af",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize72Trials(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/all72_results.json',df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e64c61",
   "metadata": {},
   "source": [
    "# With Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e313d9e",
   "metadata": {},
   "source": [
    "# (2) Linear projection followed by refinement with a physics engine. \n",
    "\n",
    "The basic idea is that you initialize the triangle location at the linear projection hypothesis, then run a simulation to see where the ball goes. Depending on whether it's above or below the exit point, adjust the triangle up or down along the linear vertical path from the initial ball position. The parameters here would be the size of the increment and the stopping criterion (number of increments or some error threshold). It would be easier (as a start) to use a deterministic model (no noise, as in Kevin's model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ac959",
   "metadata": {},
   "source": [
    "#### Do you know if people take longer to make a response for colliders farther from the midline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19faf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average response time per trial\n",
    "df_all['response_time'].mean() # 5233.517361107675 around 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44a480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['sol_distance_from_midline'] = abs(df_all['triangle_final_y'] - 300)\n",
    "df_all['gt_distance_from_midline'] = abs(df_all['obstacle_groundTruth_y'] - 300)\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "# sns.scatterplot(x='sol_distance_from_midline', y='response_time', data=df_all)\n",
    "sns.regplot(x='sol_distance_from_midline', y='response_time', data=df_all, line_kws={\"color\":\"#7F00FF\"}, scatter_kws={\"s\":5, \"color\":\"m\"})\n",
    "plt.xlabel('sol_distance_from_midline', fontsize=18)\n",
    "plt.ylabel('Response Time', fontsize=18)\n",
    "\n",
    "# Use tight_layout to automatically adjust subplot parameters to give specified padding\n",
    "plt.tight_layout()\n",
    "# plt.title('Scatter Plot of Distance_From_Mid vs Response Time')\n",
    "plt.savefig('Sol_Distance_From_Mid vs RT.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaeff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating regression\n",
    "from scipy.stats import linregress\n",
    "regression_result = linregress(df_all['sol_distance_from_midline'], df_all['response_time'])\n",
    "print(f\"Slope: {regression_result.slope}\")\n",
    "print(f\"Intercept: {regression_result.intercept}\")\n",
    "print(f\"R-squared: {regression_result.rvalue**2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7034aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a constant to the model\n",
    "X = sm.add_constant(df_all['sol_distance_from_midline'])  # Independent variable\n",
    "y = df_all['response_time']  # Dependent variable\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13711967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot(x='gt_distance_from_midline', y='response_time', data=df_all)\n",
    "sns.regplot(x='gt_distance_from_midline', y='response_time', data=df_all, line_kws={\"color\":\"#7F00FF\"}, scatter_kws={\"s\":5, \"color\":\"m\"})\n",
    "plt.xlabel('gt_distance_from_midline', fontsize=18)\n",
    "plt.ylabel('Response Time', fontsize=18)\n",
    "# plt.title('Scatter Plot of Distance_From_Mid vs Response Time')\n",
    "# Use tight_layout to automatically adjust subplot parameters to give specified padding\n",
    "plt.tight_layout()\n",
    "plt.savefig('GT_Distance_From_Mid vs RT.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee8ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_result_gt = linregress(df_all['gt_distance_from_midline'], df_all['response_time'])\n",
    "# print(f\"Slope: {regression_result_gt.slope}\")\n",
    "# print(f\"Intercept: {regression_result_gt.intercept}\")\n",
    "# print(f\"R-squared: {regression_result_gt.rvalue**2}\")\n",
    "print(regression_result_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b6f89",
   "metadata": {},
   "source": [
    "## Determine the Exit Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef78e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "exitPoints_two = allData.groupby('stimulus_idx')['projected_line_1'].first().values\n",
    "exitPoints_single = [points[0] for points in exitPoints_two] # pick one point from the line\n",
    "print(len(exitPoints_single))\n",
    "# x_projs = x_model\n",
    "# print(x_projs)\n",
    "# y_projs = y_model\n",
    "# print(y_projs)\n",
    "ball_Xs = [322.3, 322.3, 322.3, 322.3, 500 , 500 , 500 , 500 , 604.4, 604.4, 604.4, 604.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72ae197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClosestPoint(point, point_list):\n",
    "    x, y = point\n",
    "    # Use min with a key function that calculates the absolute difference between x and x*.\n",
    "    # this criteria is when x the same, get the position of y\n",
    "    closest_point = min(point_list, key=lambda p: abs(p[0] - x))\n",
    "    return closest_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4933ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gt_model = df_all.groupby(['stimulus_idx','obstacle_idx'])['obstacle_groundTruth_x'].first().values\n",
    "y_gt_model = df_all.groupby(['stimulus_idx','obstacle_idx'])['obstacle_groundTruth_y'].first().values\n",
    "print(x_gt_model[0],y_gt_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5504f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very similar to getBICFromPrediction, instead of return the BIC, only return the mle_all\n",
    "def find_best_cov_model2(x_model, y_model, df_all):\n",
    "    positions = np.sort(df_all['stimulus_idx'].unique())\n",
    "    anchors = np.sort(df_all['obstacle_idx'].unique())\n",
    "    \n",
    "    # Aggregate data from all conditions\n",
    "    all_data = np.array([df_all[(df_all['stimulus_idx'] == pos) & (df_all['obstacle_idx'] == anc)][['triangle_final_x_flipback', 'triangle_final_y']].values for pos in positions for anc in anchors])\n",
    "#     print(len(all_data),len(all_data[0]))\n",
    "    \n",
    "    # Mean models for all conditions\n",
    "    all_mean_models = np.array([x_model, y_model]).T\n",
    "    print(len(all_mean_models),len(all_mean_models))\n",
    "\n",
    "    # Find a single best-fit covariance matrix for all conditions\n",
    "    optimized_covariance, mle_all = find_single_best_covariance(all_data, all_mean_models, 'Powell')\n",
    "    \n",
    "    return optimized_covariance, mle_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ece9d",
   "metadata": {},
   "source": [
    "## Converting the above code into OOP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d00e0b",
   "metadata": {},
   "source": [
    "## Adjustment Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e1d37789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjustment for a single set of parameters given a condition (stimulus_idx, obstacle_idx)\n",
    "class SimulationScenario:\n",
    "    def __init__(self, df_all, stimulus_idx, obstacle_idx, x_init, y_init, ball_Xs, x_blue_range, exitPoints_single, initChoice, stopSignal, maxSteps, debug = False):\n",
    "        self.stimulus_idx = stimulus_idx # stimulus_idx, 1-12, int\n",
    "        self.obstacle_idx = obstacle_idx # anchor_idx, 1-6, int\n",
    "        self.x_init = x_init # initial x coords of the obstacle, 2-d list, [stimulus_idx, obstacle_idx], shape: (12,6)\n",
    "        self.y_init = y_init # initial y coords of the obstacle, 2-d list, [stimulus_idx, obstacle_idx], shape: (12,6)\n",
    "        self.ball_X = ball_Xs[stimulus_idx - 1] # initial ball position (to be fed into the js script), len(ball_Xs)=12\n",
    "        self.exit_point = exitPoints_single[stimulus_idx - 1] # actual exit point of the ball, len(exitPoints_single)=12\n",
    "        self.initChoice = initChoice # choice of initialization, ['LP', 'Anchor', 'Mid'], str\n",
    "        self.stopSignal = stopSignal # choice of stopping criteria, ['exitPoint', 'pathSim'], str\n",
    "        self.maxSteps = maxSteps # number of max adjustment, [np.inf, 0, 1, 2, 5, 10, 15, 20, 25, 30, 50]\n",
    "        self.x_blue_range = x_blue_range\n",
    "\n",
    "        # Filter dataset for the specific stimulus and obstacle index\n",
    "        self.subset = df_all[(df_all['stimulus_idx'] == stimulus_idx) & (df_all['obstacle_idx'] == obstacle_idx)]\n",
    "        self.exactPath = self.subset['exact_path_single'].iloc[0]  # Extract the exact path of the first row (the same for all rows in the subset) for comparison\n",
    "        self.exactPath_entry, self.exactPath_exit = pickPointsOutScreen(self.exactPath, top_y, bottom_y, left_x, right_x, ball_radius)\n",
    "        \n",
    "        self.x_sol = None\n",
    "        self.y_sol = None\n",
    "        self.n_steps = 0 \n",
    "        \n",
    "        # track the adjustment history\n",
    "        self.sol_history = []\n",
    "        self.sol_fd_history = []\n",
    "        self.simulated_path_history = []\n",
    "\n",
    "        # printing & debugging\n",
    "        self.debug = debug\n",
    "        \n",
    "    def set_initial_solution(self):\n",
    "        \"\"\"\n",
    "        Set the initial x and y solution based on the initialization choice.\n",
    "        \"\"\"\n",
    "        self.x_sol = self.x_init[self.stimulus_idx - 1][self.obstacle_idx - 1]\n",
    "        # 'LP' (Linear Projection)/'Mid' initialization\n",
    "        if self.initChoice in ['LP', 'Mid']:\n",
    "            self.y_sol = self.y_init[self.stimulus_idx - 1][self.obstacle_idx - 1]\n",
    "        # 'Anchor' initialization <-- old code, corrected for improvements\n",
    "        elif self.initChoice == 'Anchor':\n",
    "            self.y_sol = self.y_init[self.stimulus_idx][self.obstacle_idx]\n",
    "#         Heuristic adjustment: if initial y position is outside the screen, bring it within the screen bounds\n",
    "        if self.y_sol <= 150: self.y_sol = 150 # might be also corrected by setting the blue region\n",
    "        \n",
    "\n",
    "    def create_directory(self):\n",
    "#         self.directory = os.path.dirname(f'runSimulation/Model2_by72Trials/{self.stimulus_idx}-{self.obstacle_idx}/')\n",
    "        self.directory = os.path.dirname(f'runSimulation/Model2_by72Trials/Simulation Results-All/')\n",
    "        if not os.path.exists(self.directory):\n",
    "            os.makedirs(self.directory, exist_ok=True)\n",
    "        \n",
    "        # Define file path for simulation results\n",
    "        self.file_path = f'{self.directory}/simulation-results-{self.ball_X}-{int(self.x_sol)}-{int(self.y_sol)}.json'\n",
    "\n",
    "    def run_simulation(self):\n",
    "        self.create_directory()\n",
    "        if not os.path.exists(self.file_path):\n",
    "            subprocess.run([\n",
    "                \"node\", \"runSimulation/Model2_by72Trials/simulateFunc.js\",\n",
    "                str(self.stimulus_idx), str(self.obstacle_idx), str(self.ball_X), str(self.x_sol), str(self.y_sol)\n",
    "            ], check=True)\n",
    "    \n",
    "        # Load simulation results\n",
    "#         print(self.file_path)\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        self.simulation_results = pd.json_normalize(data)\n",
    "        self.simulated_path = self.simulation_results['simulated_trial'].iloc[0]\n",
    "#         print(self.simulated_path)\n",
    "        \n",
    "    def get_closest_point(self, point_list):\n",
    "        \"\"\"\n",
    "        Find the point in point_list that is horizontally closest to the actual exit point.\n",
    "        \"\"\"\n",
    "        # Use min with a key function that calculates the horizontal distance\n",
    "        closest_point = min(point_list, key=lambda p: (p[0] - self.exit_point[0])**2)\n",
    "        return closest_point\n",
    "    \n",
    "    def eval_by_FD(self):\n",
    "        # Calculate Frechet distances between simulated and exact paths for points out of screen\n",
    "#         l1_p, l2_p = pickPointsOutScreen(self.simulated_path, top_y, bottom_y, left_x, right_x, ball_radius)\n",
    "#         l1_g, l2_g = pickPointsOutScreen(self.exactPath, top_y, bottom_y, left_x, right_x, ball_radius)\n",
    "        self.simulatedPath_entry, self.simulatedPath_exit = pickPointsOutScreen(self.simulated_path, top_y, bottom_y, left_x, right_x, ball_radius)\n",
    "        if len(self.simulatedPath_exit) != 0 and len(self.simulatedPath_entry) != 0:\n",
    "            self.sol_fd1 = frechet_dist(self.simulatedPath_entry, self.exactPath_entry)\n",
    "            self.sol_fd2 = frechet_dist(self.simulatedPath_exit, self.exactPath_exit)\n",
    "            if self.debug:\n",
    "                print('fd_1, fd_2: ')\n",
    "                print(self.sol_fd1, self.sol_fd2)\n",
    "            self.sol_fd_history.append(self.sol_fd1+self.sol_fd2) # every time fd is evaluated, the result is appended, so fd_history length is not the actual adjustment \n",
    "        else: \n",
    "            print(self.file_path)\n",
    "            print(self.stimulus_idx, self.obstacle_idx)\n",
    "            raise Exception(f\"Please Check the Source File {self.file_path}\")\n",
    "        \n",
    "    def out_of_valid_region(self):\n",
    "        # new bound\n",
    "        if self.x_sol < self.x_blue_range[(self.stimulus_idx,self.obstacle_idx)][0] or self.x_sol > self.x_blue_range[(self.stimulus_idx,self.obstacle_idx)][1]:\n",
    "            if self.debug:\n",
    "                print(self.x_sol)\n",
    "                print(f'Bound: {self.x_blue_range[(self.stimulus_idx,self.obstacle_idx)][0], self.x_blue_range[(self.stimulus_idx,self.obstacle_idx)][1]}')\n",
    "                print('Out of Bound, Stop Adjust')\n",
    "            return True\n",
    "        if self.y_sol < 150 + margin or self.y_sol > 450 - margin:\n",
    "            if self.debug:\n",
    "                print(self.y_sol)\n",
    "                print('Out of Bound, Stop Adjust')\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "        \n",
    "    def stop_adjust(self, epsilon):\n",
    "        \"\"\"\n",
    "        Determine if the adjustment process should stop based on the stopping criteria.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Terminate if the solution has been evaluated before\n",
    "        # if any(np.isclose(self.x_sol, x) and np.isclose(self.y_sol, y) for x, y in self.sol_history):\n",
    "        # # if [self.x_sol, self.y_sol] in self.sol_history:\n",
    "        #     if self.debug:\n",
    "        #         print('In adjust history, Stop Adjust')\n",
    "        #         print([self.x_sol, self.y_sol], self.sol_history)\n",
    "        #     return True\n",
    "\n",
    "        # out of bounds\n",
    "        if self.out_of_valid_region():\n",
    "            return True\n",
    "        \n",
    "        # Stopping criteria\n",
    "        if self.stopSignal == 'exitPoint':\n",
    "            # Calculate delta_y within the method and removed delta_y as a parameter\n",
    "            x_e, y_e = self.get_closest_point(self.simulated_path)\n",
    "            delta_y = self.exit_point[1] - y_e\n",
    "            return abs(delta_y) < epsilon\n",
    "        \n",
    "        elif self.stopSignal == 'pathSim':\n",
    "            return self.sol_fd1 + self.sol_fd2 < epsilon  # Epsilon is a threshold for path similarity\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    \n",
    "    # New Adjustment function (method 1), adjust in both x and y, loop through 8 directions, choose the best\n",
    "    def adjust_obstacle(self, d, epsilon):\n",
    "        \"\"\"\n",
    "        Adjust the obstacle's position to align the simulated exit point with the actual exit point.\n",
    "\n",
    "        Parameters:\n",
    "        - d: The magnitude of each adjustment step.\n",
    "        - epsilon: The stopping criteria tolerance for vertical distance to the exit point/exit path similarity\n",
    "        \"\"\"\n",
    "        # Set initial solution based on the chosen initialization method\n",
    "        self.set_initial_solution()\n",
    "\n",
    "        # Run simulation for the initialization\n",
    "        self.run_simulation() # get self.simulated_path\n",
    "        self.eval_by_FD() # append fd for the first time, get self.sol_fd1, self_sol_fd2\n",
    "\n",
    "        # initialize best result\n",
    "        opt_distance = (self.sol_fd1 + self.sol_fd2) if self.stopSignal == 'pathSim' else abs(self.exit_point[1] - self.get_closest_point(self.simulated_path)[1])\n",
    "\n",
    "        # Main loop for the adjustment process\n",
    "\n",
    "        # if no adjustment needed, then record the results and return\n",
    "        if self.stop_adjust(epsilon):\n",
    "#             print('Adjustment Stops')\n",
    "            self.sol_history.append([self.x_sol, self.y_sol])\n",
    "            self.simulated_path_history.append(self.simulated_path)\n",
    "        \n",
    "        # otherwise, start adjustment\n",
    "        else:\n",
    "#             print('Adjustment Continues')\n",
    "            # add current solution to the history\n",
    "            self.sol_history.append([self.x_sol, self.y_sol])\n",
    "            self.simulated_path_history.append(self.simulated_path)\n",
    "            \n",
    "            # start adjustment loop\n",
    "            d_diag = d/2*(2**0.5) # adjust by d_diag in x/y direction\n",
    "            while self.n_steps < self.maxSteps:\n",
    "                if self.debug:\n",
    "                    if self.n_steps % 10 == 1:\n",
    "                        print(f'steps: {self.n_steps}')\n",
    "                        print(x_blue_range[(self.stimulus_idx,self.obstacle_idx)])\n",
    "                        print(self.x_sol, self.y_sol)\n",
    "                        print(f'Checking Stopping Criteria, best outcome: {opt_distance}')\n",
    "#                 if np.random.random() < 0.005: \n",
    "#                     print(':) Adjusting')\n",
    "#                     print(self.n_steps)\n",
    "#                     print(self.x_sol, self.y_sol)\n",
    "                # Define directions for adjustment: (dx, dy)\n",
    "                directions = [\n",
    "                    (0, -d),  # Up\n",
    "                    (0, d),  # Down\n",
    "                    (-d, 0),  # Left\n",
    "                    (d, 0),  # Right\n",
    "                    (d_diag, -d_diag),  # Right-Up\n",
    "                    (d_diag, d_diag),  # Right-Down\n",
    "                    (-d_diag, -d_diag),  # Left-Up\n",
    "                    (-d_diag, d_diag)  # Left-Down\n",
    "                ]\n",
    "\n",
    "                # Evaluate all directions and select the best one\n",
    "                results = []\n",
    "                if self.debug:\n",
    "                    print('Looping through directions')\n",
    "                    print(f'Old Result: {self.x_sol, self.y_sol}')\n",
    "\n",
    "                # Store the original solution to revert after trying each adjustment\n",
    "                original_x, original_y = self.x_sol, self.y_sol\n",
    "                \n",
    "                for dx, dy in directions:\n",
    "                    # Adjust x and y positions based on the direction\n",
    "                    new_x_sol = self.x_sol + dx\n",
    "                    new_y_sol = self.y_sol + dy\n",
    "\n",
    "                    # Run the simulation with the new adjusted positions\n",
    "                    self.x_sol = new_x_sol\n",
    "                    self.y_sol = new_y_sol\n",
    "\n",
    "                    # but only run it when the adjusted positions are within bounds\n",
    "                    if not self.out_of_valid_region():\n",
    "                        self.run_simulation()\n",
    "                        self.eval_by_FD() # append fd for the try-outs into the fd_history, new sol_fd1, sol_fd2 generated\n",
    "\n",
    "                        # Calculate criteria based on stopSignal\n",
    "                        if self.stopSignal == 'exitPoint':\n",
    "                            x_e, y_e = self.get_closest_point(self.simulated_path)\n",
    "                            delta_y = abs(self.exit_point[1] - y_e)\n",
    "                            results.append((delta_y, new_x_sol, new_y_sol, self.simulated_path))\n",
    "                        elif self.stopSignal == 'pathSim':\n",
    "                            fd_combined = self.sol_fd1 + self.sol_fd2\n",
    "                            results.append((fd_combined, new_x_sol, new_y_sol, self.simulated_path))\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        results.append((np.infty, new_x_sol, new_y_sol, None))\n",
    "\n",
    "                    # reset values of self.x_sol, self.y_sol\n",
    "                    self.x_sol, self.y_sol = original_x, original_y\n",
    "                \n",
    "                if self.debug:\n",
    "                    print([item[0] for item in results])\n",
    "\n",
    "                # Find the direction with the best outcome\n",
    "                best_result = min(results, key=lambda r: r[0])\n",
    "                best_dis, best_x_sol, best_y_sol, best_simulated_path = best_result\n",
    "\n",
    "                # Check if the best direction improves upon the current solution\n",
    "                if best_dis < opt_distance:\n",
    "                    # update opt_distance\n",
    "                    opt_distance = best_dis\n",
    "\n",
    "                    # Set the best solution found in this iteration\n",
    "                    self.x_sol = best_x_sol\n",
    "                    self.y_sol = best_y_sol\n",
    "                    self.simulated_path = best_simulated_path\n",
    "                    self.n_steps += 1\n",
    "\n",
    "                    # Call eval_by_FD to update sol_fd1 and sol_fd2 with the best solution found\n",
    "                    # attach the best fd again (the fd for each actual adjustment will appear twice in the history)\n",
    "                    self.eval_by_FD()\n",
    "\n",
    "                    # Append history\n",
    "                    if self.debug:\n",
    "                        print(f'Appending better solution: {self.x_sol, self.y_sol}')\n",
    "                        \n",
    "                    self.sol_history.append([self.x_sol, self.y_sol])\n",
    "                    self.simulated_path_history.append(self.simulated_path)\n",
    "\n",
    "                    if self.debug:\n",
    "                        print('Best Result After Adjustment')\n",
    "                        print(best_result[0], best_result[1], best_result[2])\n",
    "                else: \n",
    "                    # Stop if no improvement\n",
    "                    # if no improvements, fd will not be appended to the history again\n",
    "                    if self.debug:\n",
    "                        print('No Better Adjustments')\n",
    "                    break\n",
    "\n",
    "                # Check if the stopping criteria are met\n",
    "                if self.stop_adjust(epsilon):\n",
    "                    break\n",
    "\n",
    "        # Return all the information, including histories and last Frechet distances\n",
    "        return {\n",
    "            'x_sol': self.x_sol,\n",
    "            'y_sol': self.y_sol,\n",
    "            'n_steps': self.n_steps,\n",
    "            'sol_history': self.sol_history,\n",
    "            'fd_history': self.sol_fd_history, # might contain fd for all 8 directions\n",
    "            'simulated_path_history': self.simulated_path_history\n",
    "        }\n",
    "\n",
    "    \n",
    "    ### code for visualizing\n",
    "    \n",
    "\n",
    "    def visualize_adjustment_process(self, modelName, showPath = True):\n",
    "        fig, ax = plt.subplots(figsize=(9, 6), dpi=200)\n",
    "        ax.set_xlim(100, 900)\n",
    "        ax.set_ylim(60, 540)\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_title(f'Stimulus {self.stimulus_idx}, Obstacle {self.obstacle_idx}')\n",
    "        \n",
    "        print(self.sol_history)\n",
    "    \n",
    "        subset = drawInitialSetUp(ax, df_all, self.stimulus_idx, self.obstacle_idx)\n",
    "\n",
    "        # Draw Participant Responses\n",
    "        ax.scatter(subset[\"triangle_final_x_flipback\"], subset[\"triangle_final_y\"], s=50, marker = '+', color = '#0A704E', alpha = 1)\n",
    "\n",
    "        # Human Average FD\n",
    "        human_fd = subset['fd_combined'].mean()\n",
    "#         print(human_fd)\n",
    "#         print(self.sol_fd_history)\n",
    "        \n",
    "#         # Calculate normalized differences and map to colors with controlled scaling\n",
    "#         fd_differences = np.abs(np.array(self.sol_fd_history) - self.subset['fd_combined'].mean())\n",
    "#         if (fd_differences.max() - fd_differences.min()) != 0:\n",
    "#                 normalized_differences = (fd_differences - fd_differences.min()) / (fd_differences.max() - fd_differences.min())\n",
    "#         else:\n",
    "#             # If all values are the same, set them to the middle of the scale (0.5 is arbitrary and can be adjusted)\n",
    "#             normalized_differences = np.full_like(fd_differences, fill_value=0.5)\n",
    "        \n",
    "# #         print(normalized_differences)\n",
    "#         # Define lower and upper bounds for the color scaling\n",
    "#         lower_bound = 0\n",
    "#         upper_bound = 0.6\n",
    "#         scaled_differences = lower_bound + (upper_bound - lower_bound) * normalized_differences\n",
    "        \n",
    "#         colors = [plt.cm.YlOrBr(1 - diff) for diff in scaled_differences]  # Using scaled differences\n",
    "\n",
    "\n",
    "        colors = [plt.cm.YlOrBr(index/len(self.sol_history)) for index, item in enumerate(self.sol_history)]\n",
    "        \n",
    "        # Initial placement for the moving obstacle\n",
    "        obstacle_patch = patches.RegularPolygon(\n",
    "            (self.sol_history[0][0], self.sol_history[0][1]), numVertices=3, radius=45, orientation=np.pi, color=colors[0], zorder=7\n",
    "        )\n",
    "        ax.add_patch(obstacle_patch)\n",
    "\n",
    "        # Plot list of x markers and dashed lines (for cumulative path)\n",
    "        cumulative_path_x = []\n",
    "        cumulative_path_y = []\n",
    "\n",
    "        lines = []  # Store line objects to keep all on plot\n",
    "\n",
    "        def init():\n",
    "            # Initialize with empty paths\n",
    "            cumulative_path_x.clear()\n",
    "            cumulative_path_y.clear()\n",
    "            return obstacle_patch,\n",
    "\n",
    "        def update(frame):\n",
    "            # Update the obstacle position\n",
    "            obstacle_patch.xy = (self.sol_history[frame][0], self.sol_history[frame][1])\n",
    "            obstacle_patch.set_color(colors[frame])\n",
    "\n",
    "            # Add trajectory lines\n",
    "            # Specifically, darker lines indicate trajectories whose Fréchet distance ($fd$) is \n",
    "            # closer to the average Fréchet distance of human responses ($fd_{human}$) for that condition.\n",
    "            if frame < len(self.simulated_path_history):\n",
    "                simulated_path = np.array(self.simulated_path_history[frame])\n",
    "                alpha = frame / len(self.sol_history)  # Normalize alpha value\n",
    "                obstacle_patch.set_alpha(min(1, 0.5 + alpha * 0.5))\n",
    "                line, = ax.plot(simulated_path[:, 0], simulated_path[:, 1], color=colors[frame], linewidth=2, alpha=min(1, 0.5 + alpha * 0.5), zorder=7)\n",
    "                lines.append(line)\n",
    "\n",
    "                if showPath:\n",
    "                    # Append current position to the cumulative path\n",
    "                    cumulative_path_x.append(self.sol_history[frame][0])\n",
    "                    cumulative_path_y.append(self.sol_history[frame][1])\n",
    "\n",
    "                    # Plot cumulative path as x-x-x-x\n",
    "                    ax.plot(cumulative_path_x, cumulative_path_y, linestyle='-', marker='o', color='darkgray', markersize=2, linewidth=1, alpha=min(1, 0.5 + alpha * 0.5), zorder=7)\n",
    "            return lines + [obstacle_patch]\n",
    "\n",
    "        frames = len(self.sol_history)\n",
    "        ani = FuncAnimation(fig, update, init_func=init, frames=frames, blit=True, repeat=False)\n",
    "\n",
    "        # Add a global legend\n",
    "        handles = [\n",
    "            patches.Patch(color=ground_truth_color, label='Ground Truth'),\n",
    "            patches.Patch(color=human_centroid_color, label='Human Centroid'),\n",
    "            patches.Patch(color='#0A704E', label='Participant Responses'),\n",
    "            patches.Patch(color=participant_color, label='Participant Trajectories'),\n",
    "            patches.Patch(color=anchor_color, label='Anchor Position'),\n",
    "            patches.Patch(color=plt.cm.YlOrBr(0.5), label='Model Prediction')\n",
    "        ]\n",
    "\n",
    "        # Add the legend outside the plot\n",
    "        leg = fig.legend(handles=handles, loc='upper center', bbox_to_anchor=(0.5, 1), ncol=3, fontsize='10')\n",
    "\n",
    "        from pathlib import Path\n",
    "\n",
    "        # Create the directory\n",
    "        animation_dir = Path(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/adjustment_animation')\n",
    "        animation_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Save the animation\n",
    "        ani.save(animation_dir / f'adjustment_animation_{self.stimulus_idx}-{self.obstacle_idx}.gif', writer='pillow', fps=1)\n",
    "        plt.close(fig)  # Prevent double display in Jupyter Notebook\n",
    "\n",
    "        # To display the animation in a Jupyter notebook\n",
    "        from IPython.display import HTML\n",
    "        return HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f553ad0",
   "metadata": {},
   "source": [
    "A very sensible code explanation provided by ChatGPT (new):\n",
    "\n",
    "### 1. **Initialization (`__init__` method)**:\n",
    "   - The `SimulationScenario` class is designed to simulate a specific scenario where a ball interacts with an obstacle in a predefined environment.\n",
    "   - When an instance is created, it takes in various parameters related to the simulation, such as the stimulus and obstacle indices, initial positions of obstacles, the initial position of the ball, exit points, initialization and stopping criteria, and maximum steps for adjustment.\n",
    "   - It filters a dataset (`df_all`) to focus on a specific scenario based on the provided stimulus and obstacle indices, and it extracts the exact path for comparison purposes.\n",
    "\n",
    "### 2. **Setting Initial Solution (`set_initial_solution` method)**:\n",
    "   - This method initializes the x and y positions of the obstacle based on the selected initialization strategy (e.g., Linear Projection, Anchor, or Mid).\n",
    "   - It includes a heuristic adjustment to ensure the initial y position is within screen bounds.\n",
    "\n",
    "### 3. **Creating Directory and Running Simulation (`create_directory` and `run_simulation` methods)**:\n",
    "   - `create_directory`: Creates a directory for storing simulation results based on the stimulus and obstacle indices.\n",
    "   - `run_simulation`: Runs a simulation using an external JavaScript file (`simulateFunc.js`) and stores the results in a JSON file. If the file doesn’t exist, it creates one by running the simulation.\n",
    "\n",
    "### 4. **Evaluating Path Similarity (`eval_by_FD` method)**:\n",
    "   - This method calculates the similarity between the simulated path and the exact path using the Fréchet distance. It checks whether the simulated path closely follows the exact path based on entry and exit points.\n",
    "\n",
    "### 5. **Stopping Criteria (`stop_adjust` method)**:\n",
    "   - This method determines whether the adjustment process should stop based on several criteria:\n",
    "     - If the x or y position of the obstacle is out of bounds.\n",
    "     - If the solution has already been evaluated.\n",
    "     - Based on the chosen stopping criteria (`exitPoint` or `pathSim`), it checks whether the simulation results are close enough to the expected outcome.\n",
    "\n",
    "### 6. **Adjusting the Obstacle (`adjust_obstacle` method)**:\n",
    "   - The main function of the class, this method iteratively adjusts the position of the obstacle to better align the simulated exit point with the actual exit point.\n",
    "   - It evaluates different directions of adjustment (up, down, left, right, and diagonals) and selects the best one based on the simulation results.\n",
    "   - The process continues until the stopping criteria are met or the maximum number of steps is reached. The method returns all relevant information, including the history of adjustments and path similarities.\n",
    "\n",
    "### 7. **Visualization (`visualize_adjustment_process` method)**:\n",
    "   - This method visualizes the adjustment process by creating an animation that shows how the obstacle’s position changes over time and how the simulated path evolves.\n",
    "   - It generates a GIF of the adjustment process and displays it, making it easier to understand how the simulation progresses.\n",
    "\n",
    "### **Summary**:\n",
    "   - The code is part of a simulation tool that iteratively adjusts the position of an obstacle to achieve a desired outcome, specifically aligning the simulated path of a ball with an expected path.\n",
    "   - It involves initializing the scenario, running simulations, evaluating the results, making adjustments, and visualizing the process.\n",
    "   - The goal is to fine-tune the obstacle’s position using a systematic approach, guided by the chosen initialization and stopping criteria, to achieve the best possible alignment between the simulated and actual paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93ca284",
   "metadata": {},
   "source": [
    "A very sensible code explanation provided by ChatGPT (previous):\n",
    "\n",
    "The adjustment process in your `SimulationScenario` class involves modifying the position of an obstacle in a simulated environment to align the simulated exit point of a ball with its actual exit point. The process iterates through potential positions of the obstacle, adjusting based on the difference between the current simulated exit and the actual exit point, while respecting the conditions imposed by the stopping criteria.\n",
    "\n",
    "### Explanation of the Adjustment Process\n",
    "\n",
    "1.  **Initialization**: The initial position of the obstacle is set based on predefined initial conditions (`x_init` and `y_init`). This might involve different strategies like midpoint initialization or based on specific anchor points.\n",
    "    \n",
    "2.  **Running Simulation**: The obstacle's initial position is used to run a physics simulation (presumably via a JavaScript Node.js script) to see where a ball would exit if it interacted with the obstacle positioned at those coordinates.\n",
    "    \n",
    "3.  **Adjustment Loop**:\n",
    "    \n",
    "    *   The simulation's exit point is compared to the actual exit point.\n",
    "    *   If the simulated exit point (vertical position `y_e`) is less than the actual exit point (`y_exit`), the obstacle is moved downwards, otherwise, it is moved upwards by a step size `d`.\n",
    "    *   This adjustment is repeated, modifying the obstacle's position incrementally and re-running the simulation after each adjustment.\n",
    "4.  **Stopping Criteria**:\n",
    "    \n",
    "    *   The adjustment loop can stop if the vertical position of the obstacle moves out of predefined screen bounds.\n",
    "    *   It can also stop if the obstacle's adjusted position repeats (cyclic adjustments indicating a local minimum or a configuration that doesn’t converge).\n",
    "    *   Currently, it stops if the vertical distance to the actual exit point is less than the threshold `epsilon`, indicating the simulated exit is sufficiently close to the actual exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positions)\n",
    "print(anchors)\n",
    "print(ball_Xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cbaf42",
   "metadata": {},
   "source": [
    "## Function for running the whole simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "69181e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_parameters(df_all, positions, anchors, ball_Xs, x_blue_range, exitPoints_single, \n",
    "                         d_values, epsilon_values, max_adjustments, \n",
    "                         x_init, y_init, init_choice, stop_signal, debug):\n",
    "    \n",
    "    # Initialize dict for storing the single best-fit parameters & history\n",
    "    best_params = {\n",
    "        'd': None,\n",
    "        'epsilon': None,\n",
    "        'maxSteps': None,\n",
    "        'best_ml': -np.inf,\n",
    "        'best_cov': None,\n",
    "        'best_x': [],\n",
    "        'best_y': [],\n",
    "        'adjustment_histories': [],\n",
    "        'best_n_steps': None\n",
    "    }\n",
    "    \n",
    "    for d in d_values:\n",
    "        print(f'TESTING d = {d}...')\n",
    "        for epsilon in epsilon_values:\n",
    "            print(f'TESTING epsilon = {epsilon}...')\n",
    "            for maxSteps in max_adjustments:\n",
    "                print(f'TESTING max_steps = {maxSteps}...')\n",
    "                x_sols, y_sols, n_steps, histories = [], [], [], []\n",
    "                for stimulus_idx in positions:\n",
    "                    for obstacle_idx in anchors:\n",
    "                        # Initialize the simulation scenario\n",
    "                        simulation_scenario = SimulationScenario(\n",
    "                            df_all, stimulus_idx, obstacle_idx, x_init, y_init,\n",
    "                            ball_Xs, x_blue_range, exitPoints_single, init_choice, stop_signal, maxSteps, debug\n",
    "                        )\n",
    "                        # Run the adjustment process\n",
    "                        # result = simulation_scenario.adjust_obstacle(d, epsilon)\n",
    "                        try:\n",
    "                            result = simulation_scenario.adjust_obstacle(d, epsilon)\n",
    "                            # print(f\"for {stimulus_idx}, {obstacle_idx}, x_sol is {result['x_sol']}\")\n",
    "                            x_sols.append(result['x_sol'])\n",
    "                            y_sols.append(result['y_sol'])\n",
    "                            n_steps.append(result['n_steps'])\n",
    "                            histories.append({\n",
    "                                'sol_history': result['sol_history'],\n",
    "                                'fd_history': result['fd_history'],\n",
    "                                'simulated_path_history': result['simulated_path_history']\n",
    "                            })\n",
    "                            print(f'Done with {stimulus_idx}-{obstacle_idx}')\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error encountered with stimulus_idx {stimulus_idx}, obstacle_idx {obstacle_idx}: {e}\")\n",
    "                            print(result['x_sol'], result['y_sol'])\n",
    "                            continue\n",
    "#                         print('--------------------------------------')\n",
    "                        # if np.random.random() < 0.00001:\n",
    "                        #     print('Visualization')\n",
    "                        #     simulation_scenario.visualize_adjustment_process(modelName)\n",
    "\n",
    "                if len(x_sols) == 12 and len(y_sols) == 12:\n",
    "                    print('Correcting Size Mismatch...')\n",
    "                    x_sols = [x_sol for x_sol in x_sols for _ in range(6)]\n",
    "                    y_sols = [y_sol for y_sol in y_sols for _ in range(6)]\n",
    "                # Evaluate the model, assume find_best_cov_model2 is a function that returns (cov, ml)\n",
    "                if len(x_sols) == len(y_sols) and len(x_sols) == 72:\n",
    "                    print('Evaluating MLL')\n",
    "                    cov, ml = find_best_cov_model2(x_sols, y_sols, df_all)  # Example function\n",
    "                else: \n",
    "                    print(f'MLL not Evaluated!!! ERROR {d}, {epsilon}, {maxSteps}')\n",
    "                \n",
    "                # Update the best parameters if the new model likelihood is better\n",
    "                print('Current MLL, New MLL:')\n",
    "                print(ml, best_params['best_ml'])\n",
    "                if ml > best_params['best_ml']:\n",
    "                    best_params.update({\n",
    "                        'd': d,\n",
    "                        'epsilon': epsilon,\n",
    "                        'maxSteps': maxSteps,\n",
    "                        'best_ml': ml,\n",
    "                        'best_cov': cov,\n",
    "                        'best_x': x_sols,\n",
    "                        'best_y': y_sols,\n",
    "                        'adjustment_histories': histories,\n",
    "                        'best_n_steps':n_steps\n",
    "                    })\n",
    "                    \n",
    "                print(f'DONE TESTING max_steps = {maxSteps}')\n",
    "                print('-------------------------------------')\n",
    "            print(f'DONE TESTING epsilon = {epsilon}')\n",
    "            model_dir = Path(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}')\n",
    "            model_dir.mkdir(parents=True, exist_ok=True)\n",
    "            # when not under debug mode, save results\n",
    "            if not debug:\n",
    "                with open(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/adjustment_results_covering_{d}_{epsilon}_{maxSteps}.pkl', 'wb') as f:\n",
    "                    pickle.dump(best_params, f)\n",
    "            print('***************************************')\n",
    "        print(f'DONE TESTING d = {d}')\n",
    "        print('+++++++++++++++++++++++++++++++++++++++')\n",
    "\n",
    "    return best_params\n",
    "\n",
    "# Usage of the function\n",
    "# positions = range(1, 13)  # Stimulus indices\n",
    "# anchors = range(1, 7)     # Obstacle indices\n",
    "# d_values = [1, 5, 10, 20, 40]  # Displacement magnitudes\n",
    "# epsilon_values = [1, 5, 10, 20, 40]  # Tolerance levels\n",
    "# max_adjustments = [np.inf]  # Maximum adjustment steps\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "# Example: Mid+Sim\n",
    "# x_init = [[intersections_modified_by_anchor[(stimulus_idx, obstacle_idx)][0] for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "# y_init = [[300]*6]*12\n",
    "\n",
    "# Run the function\n",
    "# best_setup = find_best_parameters(df_all, positions, anchors, ball_Xs, x_blue_range, exitPoints_single,\n",
    "#                                   d_values, epsilon_values, max_adjustments, x_init, y_init, 'Mid', 'exitPoint')\n",
    "\n",
    "# The best_setup dictionary contains the best parameters, model likelihood, and comprehensive adjustment histories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181a6784",
   "metadata": {},
   "source": [
    "## Defining the grid for free parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "be0f1062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage of the function\n",
    "positions = range(1, 13)  # Stimulus indices\n",
    "anchors = range(1, 7)     # Obstacle indices\n",
    "d_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]  # Displacement magnitudes\n",
    "# Sam's rec: A shift of 20-40 pixels is pretty large, so it's not surprising that the optimal fit never chooses those values for d. \n",
    "# I think it probably makes sense to restrict the range to 1-10 and include more values within that range.\n",
    "epsilon_values = [1, 5, 10, 20, 40]  # Tolerance levels # Exit Point\n",
    "# epsilon_values = [10, 20, 40, 80, 100, 150, 200] # Path Sim\n",
    "max_adjustments = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]  # Maximum adjustment steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "025fd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeBestParams(best_setup, modelName):\n",
    "    storeXYPrediction(best_setup['best_x'], best_setup['best_y'], modelName)\n",
    "\n",
    "    with open(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/adjustment_results.pkl', 'wb') as f:\n",
    "        pickle.dump(best_setup, f)\n",
    "\n",
    "def runEvalsFigs(modelName, df_all, n_free_params, withAdjust = False, best_setup = None):\n",
    "    result_file_path = f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/all72_results.json'\n",
    "    if not os.path.exists(result_file_path):\n",
    "        runScript_72Simulations(f'runSimulation/full72Trajectories/{modeling_choice}/run72Simulations.py', modelName)\n",
    "    with open(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/adjustment_results.pkl', 'rb') as f:\n",
    "        best_setup = pickle.load(f)\n",
    "    getBICFromPrediction(best_setup['best_x'], best_setup['best_y'], df_all, n_free_params)\n",
    "    compareFD_model_human(result_file_path, df_all, modelName)\n",
    "    visualize72Trials(result_file_path, df_all, modelName, withAdjust, best_setup)\n",
    "    # visualize72Trials(result_file_path, df_all)\n",
    "    return best_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f42fa51",
   "metadata": {},
   "source": [
    "#### if compare with a random parameter set (for results checking & debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "078c9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debugResults(d, e, mxSteps, oneAnchorOrAll, x_init, y_init, modelInit, modelStop):\n",
    "    debug_results = find_best_parameters(df_all, positions, oneAnchorOrAll, ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                            [d], [e], [mxSteps], x_init, y_init, modelInit, modelStop, True)\n",
    "    return debug_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351d6ad",
   "metadata": {},
   "source": [
    "## LP + Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0b8d6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_setup_LP_Sim = runEvalsFigs('LP+Sim', df_all, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "a9c982d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_model = [nearest_value_in_range(intersections[stimulus_idx][0],x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for stimulus_idx in positions for obstacle_idx in anchors] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "# y_model = [nearest_value_in_range(intersections[stimulus_idx][1], 150 + margin, 450 - margin) for stimulus_idx in positions for obstacle_idx in anchors]\n",
    "# for i in range(12):\n",
    "#     for j in range(6):\n",
    "#         if not y_init[i][j] == y_model[i*6+j]:\n",
    "#             print(y_init[i][j])\n",
    "#             print(y_model[i*6+j])\n",
    "#             print('Something Wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47d34bba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelName = 'LP+Sim'\n",
    "max_adjustments = [np.infty]\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "\n",
    "x_init = [[nearest_value_in_range(intersections[stimulus_idx][0], x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(intersections[stimulus_idx][1], 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "\n",
    "# Run the function\n",
    "# Results will be the same across different anchors, so can just run one anchor\n",
    "best_setup_LP_Sim = find_best_parameters(df_all, positions, [1], ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                         d_values, epsilon_values, max_adjustments, x_init, y_init, 'LP', 'exitPoint', False)\n",
    "\n",
    "storeBestParams(best_setup_LP_Sim, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'LP+Sim'\n",
    "\n",
    "storeXYPrediction(best_setup_LP_Sim['best_x'], best_setup_LP_Sim['best_y'], modelName)\n",
    "\n",
    "with open(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/adjustment_results.pkl', 'wb') as f:\n",
    "    pickle.dump(best_setup_LP_Sim, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "082436f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'LP+Sim'\n",
    "\n",
    "with open(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/adjustment_results.pkl', 'rb') as f:\n",
    "    best_setup_LP_Sim = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbb90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_LP_Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test visualization\n",
    "simulation_scenario_test = SimulationScenario(\n",
    "                            df_all, 2, 1, x_init, y_init,\n",
    "                            ball_Xs, x_blue_range, exitPoints_single, 'LP', 'exitPoint', np.infty, True)\n",
    "result = simulation_scenario_test.adjust_obstacle(15, 1)\n",
    "simulation_scenario_test.visualize_adjustment_process(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77480824",
   "metadata": {},
   "outputs": [],
   "source": [
    "getBICFromPrediction(best_setup_LP_Sim['best_x'], best_setup_LP_Sim['best_y'], df_all, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43064306",
   "metadata": {},
   "source": [
    "### FD evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d83682",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'LP+Sim'\n",
    "# runScript_72Simulations('runSimulation/full72Trajectories/run72Simulations.py', modelName)\n",
    "# compareFD_model_human(f'runSimulation/full72Trajectories/{modelName}/all72_results.json', df_all, modelName)\n",
    "# visualize72Trials(f'runSimulation/full72Trajectories/{modelName}/all72_results.json',df_all)\n",
    "best_setup_LP_Sim = runEvalsFigs('LP+Sim', df_all, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153987b2",
   "metadata": {},
   "source": [
    "### Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Results\n",
    "x_init = [[nearest_value_in_range(intersections[stimulus_idx][0], x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(intersections[stimulus_idx][1], 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "\n",
    "debug_results = debugResults(15, 1, np.infty, [1], x_init, y_init, 'LP', 'exitPoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c9a6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_results['best_ml']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c95ed5",
   "metadata": {},
   "source": [
    "## LP + Sim_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d874a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'LP+Sim_max'\n",
    "max_adjustments = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "x_init = [[nearest_value_in_range(intersections[stimulus_idx][0], x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(intersections[stimulus_idx][1], 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "\n",
    "# Run the function\n",
    "# Results will be the same across different anchors, so can just run one anchor\n",
    "best_setup_LP_Sim_max = find_best_parameters(df_all, positions, [1], ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                  d_values, epsilon_values, max_adjustments, x_init, y_init, 'LP', 'exitPoint', False)\n",
    "\n",
    "# Store the results\n",
    "storeBestParams(best_setup_LP_Sim_max, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a37b9dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'LP+Sim_max'\n",
    "\n",
    "with open(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/adjustment_results.pkl', 'rb') as f:\n",
    "    best_setup_LP_Sim_max_debug = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_LP_Sim_max = runEvalsFigs('LP+Sim_max', df_all, 5)\n",
    "print(best_setup_LP_Sim_max['best_x'])\n",
    "print(best_setup_LP_Sim_max['best_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "getBICFromPrediction(best_setup_LP_Sim_max['best_x'], best_setup_LP_Sim_max['best_y'], df_all, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test visualization\n",
    "simulation_scenario_test = SimulationScenario(\n",
    "                            df_all, 1, 1, x_init, y_init,\n",
    "                            ball_Xs, x_blue_range, exitPoints_single, 'LP', 'exitPoint', 9)\n",
    "result = simulation_scenario_test.adjust_obstacle(8, 10)\n",
    "simulation_scenario_test.visualize_adjustment_process(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d4075",
   "metadata": {},
   "source": [
    "## Anchor + Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c142d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'Anchor+Sim'\n",
    "# max_adjustments = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "max_adjustments = [np.infty]\n",
    "# anchors = np.sort(df_all['obstacle_idx'].unique())\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "x_init = [[nearest_value_in_range(anchor_Xs[stimulus_idx][obstacle_idx],x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "y_init = df_all.groupby(['stimulus_idx','obstacle_idx'])['obstacle_initial_y'].first() \n",
    "\n",
    "# Run the function\n",
    "best_setup_Anchor_sim = find_best_parameters(df_all, positions, anchors, ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                  d_values, epsilon_values, max_adjustments, x_init, y_init, 'Anchor', 'exitPoint', False)\n",
    "\n",
    "# Store the results\n",
    "storeBestParams(best_setup_Anchor_sim, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_Anchor_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_Anchor_sim = runEvalsFigs('Anchor+Sim', df_all, 4, True, best_setup_Anchor_sim)\n",
    "print(best_setup_Anchor_sim['d'],best_setup_Anchor_sim['epsilon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7a22e",
   "metadata": {},
   "source": [
    "## Anchor + Sim_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fbd27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'Anchor+Sim_max'\n",
    "max_adjustments = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "# max_adjustments = [np.infty]\n",
    "# anchors = np.sort(df_all['obstacle_idx'].unique())\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "x_init = [[nearest_value_in_range(anchor_Xs[stimulus_idx][obstacle_idx],x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "y_init = df_all.groupby(['stimulus_idx','obstacle_idx'])['obstacle_initial_y'].first() \n",
    "\n",
    "# Run the function\n",
    "best_setup_Anchor_sim_max = find_best_parameters(df_all, positions, anchors, ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                  d_values, epsilon_values, max_adjustments, x_init, y_init, 'Anchor', 'exitPoint', False)\n",
    "\n",
    "# Store the results\n",
    "storeBestParams(best_setup_Anchor_sim_max, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_Anchor_sim_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97980b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'Anchor+Sim_max'\n",
    "\n",
    "with open(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/adjustment_results.pkl', 'rb') as f:\n",
    "    best_setup_Anchor_sim_max = pickle.load(f)\n",
    "best_setup_Anchor_sim_max = runEvalsFigs(modelName, df_all, 5, True, best_setup_Anchor_sim_max)\n",
    "print(best_setup_Anchor_sim_max['d'],best_setup_Anchor_sim_max['epsilon'], best_setup_Anchor_sim_max['maxSteps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test visualization\n",
    "modelName = 'Anchor+Sim_max'\n",
    "x_init = [[intersections_modified_by_anchor[(stimulus_idx,obstacle_idx)][0] for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "y_init = df_all.groupby(['stimulus_idx','obstacle_idx'])['obstacle_initial_y'].first()\n",
    "simulation_scenario_test = SimulationScenario(\n",
    "                            df_all, 2, 1, x_init, y_init,\n",
    "                            ball_Xs, x_blue_range, exitPoints_single, 'Anchor', 'exitPoint', 3)\n",
    "result = simulation_scenario_test.adjust_obstacle(10, 10)\n",
    "simulation_scenario_test.visualize_adjustment_process(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e732aeb2",
   "metadata": {},
   "source": [
    "## Midline+Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'Mid+Sim'\n",
    "# max_adjustments = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "max_adjustments = [np.infty]\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "x_init = [[nearest_value_in_range(canvasWidth/2, x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(canvasHeight/2, 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "\n",
    "\n",
    "# Run the function\n",
    "# Results will be the same across different anchors, so can just run one anchor\n",
    "best_setup_mid_sim = find_best_parameters(df_all, positions, [1], ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                  d_values, epsilon_values, max_adjustments, x_init, y_init, 'Mid', 'exitPoint', False)\n",
    "\n",
    "# Store the results\n",
    "storeBestParams(best_setup_mid_sim, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727078cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_mid_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_mid_sim = runEvalsFigs('Mid+Sim', df_all, 4)\n",
    "print(best_setup_mid_sim['d'], best_setup_mid_sim['epsilon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab74b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Results\n",
    "modelName = 'Mid+Sim'\n",
    "x_init = [[nearest_value_in_range(canvasWidth/2, x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(canvasHeight/2, 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "debug_results = debugResults(4, 10, np.infty, [1], x_init, y_init, 'Mid', 'exitPoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3de388",
   "metadata": {},
   "source": [
    "## Mid + Sim_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce2dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'Mid+Sim_max'\n",
    "max_adjustments = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "# max_adjustments = [np.infty]\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "x_init = [[nearest_value_in_range(canvasWidth/2, x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(canvasHeight/2, 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "\n",
    "\n",
    "# Run the function\n",
    "# Results will be the same across different anchors, so can just run one anchor\n",
    "best_setup_mid_sim_max = find_best_parameters(df_all, positions, [1], ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                  d_values, epsilon_values, max_adjustments, x_init, y_init, 'Mid', 'exitPoint', False)\n",
    "\n",
    "# Store the results\n",
    "storeBestParams(best_setup_mid_sim_max, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74478d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_mid_sim_max['best_n_steps']\n",
    "#  'd': 4,\n",
    "#  'epsilon': 5,\n",
    "#  'maxSteps': 10,\n",
    "#  'best_ml': -14799.718164780481,\n",
    "#  [9, 6, 2, 1, 2, 4, 1, 5, 1, 10, 2, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9db8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_mid_sim_max = runEvalsFigs('Mid+Sim_max', df_all, 5)\n",
    "print(best_setup_mid_sim_max['d'], best_setup_mid_sim_max['epsilon'], best_setup_mid_sim_max['maxSteps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480a02e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize72Trials(f'runSimulation/full72Trajectories/{modeling_choice}/{modelName}/all72_results.json', df_all, modelName, False, best_setup_mid_sim_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac19388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test visualization\n",
    "modelName = 'Mid+Sim_max'\n",
    "x_init = [[intersections_modified_by_anchor[(stimulus_idx,obstacle_idx)][0] for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "y_init = [[300]*6]*12\n",
    "simulation_scenario_test = SimulationScenario(\n",
    "                            df_all, 2, 1, x_init, y_init,\n",
    "                            ball_Xs, exitPoints_single, 'Mid', 'exitPoint', 15)\n",
    "result = simulation_scenario_test.adjust_obstacle(1, 20)\n",
    "simulation_scenario_test.visualize_adjustment_process(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b2e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate adjustment gifs\n",
    "modelName = 'Mid+Sim_max'\n",
    "simulation_scenario_test = SimulationScenario(\n",
    "                            df_all, 5, 2, x_init, y_init,\n",
    "                            ball_Xs, x_blue_range, exitPoints_single, 'Mid', 'exitPoint', 10, True)\n",
    "result = simulation_scenario_test.adjust_obstacle(4, 5)\n",
    "simulation_scenario_test.visualize_adjustment_process(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d66872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Results\n",
    "modelName = 'Mid+Sim_max'\n",
    "x_init = [[nearest_value_in_range(canvasWidth/2, x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(canvasHeight/2, 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "debugged_results = debugResults(4, 5, 10, [1], x_init, y_init, 'Mid', 'exitPoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "runEvalsFigs(modelName, df_all, 5, False, debugged_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc055dbc",
   "metadata": {},
   "source": [
    "# Path Sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb27da8e",
   "metadata": {},
   "source": [
    "## LP + Sim_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'LP+Sim_ps'\n",
    "max_adjustments = [np.infty]\n",
    "# max_adjustments = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "epsilon_values = [10, 20, 40, 80, 100, 150, 200]  # Tolerance levels, pathSim: entry+exit path similarity\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "x_init = [[nearest_value_in_range(intersections[stimulus_idx][0], x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(intersections[stimulus_idx][1], 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "\n",
    "# Run the function\n",
    "# Results will be the same across different anchors, so can just run one anchor\n",
    "best_setup_LP_Sim_ps = find_best_parameters(df_all, positions, [1], ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                  d_values, epsilon_values, max_adjustments, x_init, y_init, 'LP', 'pathSim', False)\n",
    "\n",
    "# Store the results\n",
    "storeBestParams(best_setup_LP_Sim_ps, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807561ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_LP_Sim_ps\n",
    "# 'd': 15,\n",
    "#  'epsilon': 10,\n",
    "#  'maxSteps': inf,\n",
    "#  'best_ml': -15544.396347228148,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e60d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_LP_Sim_ps = runEvalsFigs('LP+Sim_ps', df_all, 4)\n",
    "print(best_setup_LP_Sim_ps['d'], best_setup_LP_Sim_ps['epsilon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66370b8",
   "metadata": {},
   "source": [
    "## LP + Sim_ps_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff3764",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'LP+Sim_ps_max'\n",
    "# max_adjustments = [np.infty]\n",
    "max_adjustments = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "epsilon_values = [10, 20, 40, 80, 100, 150, 200]  # Tolerance levels, pathSim: entry+exit path similarity\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "x_init = [[nearest_value_in_range(intersections[stimulus_idx][0], x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(intersections[stimulus_idx][1], 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "\n",
    "# Run the function\n",
    "# Results will be the same across different anchors, so can just run one anchor\n",
    "best_setup_LP_Sim_ps_max = find_best_parameters(df_all, positions, [1], ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                  d_values, epsilon_values, max_adjustments, x_init, y_init, 'LP', 'pathSim', False)\n",
    "\n",
    "# Store the results\n",
    "storeBestParams(best_setup_LP_Sim_ps_max, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_LP_Sim_ps_max = runEvalsFigs('LP+Sim_ps_max', df_all, 5)\n",
    "print(f\"d: {best_setup_LP_Sim_ps_max['d']}, epsilon: {best_setup_LP_Sim_ps_max['epsilon']}, maxSteps: {best_setup_LP_Sim_ps_max['maxSteps']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e818ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_LP_Sim_ps_max\n",
    "#  'd': 20,\n",
    "#  'epsilon': 10,\n",
    "#  'maxSteps': 4,\n",
    "#  'best_ml': -15478.41455064393,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12899dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try alternative combination & test if best\n",
    "modelName = 'LP+Sim_ps_max_debug'\n",
    "x_init = [[nearest_value_in_range(intersections[stimulus_idx][0], x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(intersections[stimulus_idx][1], 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "\n",
    "debuged_results = debugResults(20, 40, 4, [1], x_init, y_init, 'LP', 'pathSim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e3468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "debuged_results['best_x']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78721e10",
   "metadata": {},
   "source": [
    "## Anchor + Sim_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e4afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'Anchor+Sim_ps'\n",
    "# anchors = np.sort(df_all['obstacle_idx'].unique())\n",
    "max_adjustments = [np.infty]\n",
    "# max_adjustments = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "epsilon_values = [10, 20, 40, 80, 100, 150, 200]\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "x_init = [[nearest_value_in_range(anchor_Xs[stimulus_idx][obstacle_idx],x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "y_init = df_all.groupby(['stimulus_idx','obstacle_idx'])['obstacle_initial_y'].first()\n",
    "\n",
    "# Run the function\n",
    "best_setup_Anchor_sim_ps = find_best_parameters(df_all, positions, anchors, ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                  d_values, epsilon_values, max_adjustments, x_init, y_init, 'Anchor', 'pathSim', False)\n",
    "\n",
    "# Store the results\n",
    "storeBestParams(best_setup_Anchor_sim_ps, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce832fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_Anchor_sim_ps = runEvalsFigs(modelName, df_all, 4)\n",
    "print(best_setup_Anchor_sim_ps['d'], best_setup_Anchor_sim_ps['epsilon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_Anchor_sim_ps\n",
    "#  'd': 20,\n",
    "#  'epsilon': 10,\n",
    "#  'maxSteps': inf,\n",
    "#  'best_ml': -14931.346174071901"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0091bd0c",
   "metadata": {},
   "source": [
    "## Anchor + Sim_ps_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcddaa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'Anchor+Sim_ps_max'\n",
    "# anchors = np.sort(df_all['obstacle_idx'].unique())\n",
    "# max_adjustments = [np.infty]\n",
    "max_adjustments = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "epsilon_values = [10, 20, 40, 80, 100, 150, 200]\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "x_init = [[nearest_value_in_range(anchor_Xs[stimulus_idx][obstacle_idx],x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "y_init = df_all.groupby(['stimulus_idx','obstacle_idx'])['obstacle_initial_y'].first()\n",
    "\n",
    "\n",
    "# Run the function\n",
    "best_setup_Anchor_sim_ps_max = find_best_parameters(df_all, positions, anchors, ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                  d_values, epsilon_values, max_adjustments, x_init, y_init, 'Anchor', 'pathSim', False)\n",
    "\n",
    "# Store the results\n",
    "storeBestParams(best_setup_Anchor_sim_ps_max, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_Anchor_sim_ps_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9522ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_Anchor_sim_ps_max = runEvalsFigs('Anchor+Sim_ps_max', df_all, 5, True, best_setup_Anchor_sim_ps_max)\n",
    "print(f\"d: {best_setup_Anchor_sim_ps_max['d']}, epsilon: {best_setup_Anchor_sim_ps_max['epsilon']}, maxSteps: {best_setup_Anchor_sim_ps_max['maxSteps']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dc0975",
   "metadata": {},
   "source": [
    "## Mid + Sim_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'Mid+Sim_ps'\n",
    "max_adjustments = [np.infty]\n",
    "# max_adjustments = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "epsilon_values = [10, 20, 40, 80, 100, 150, 200]\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "x_init = [[nearest_value_in_range(canvasWidth/2, x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(canvasHeight/2, 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "\n",
    "# Run the function\n",
    "# Results will be the same across different anchors, so can just run one anchor\n",
    "best_setup_mid_sim_ps = find_best_parameters(df_all, positions, [1], ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                  d_values, epsilon_values, max_adjustments, x_init, y_init, 'Mid', 'pathSim', False)\n",
    "\n",
    "# Store the results\n",
    "storeBestParams(best_setup_mid_sim_ps, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5031d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_mid_sim_ps\n",
    "#  'd': 20,\n",
    "#  'epsilon': 10,\n",
    "#  'maxSteps': inf,\n",
    "#  'best_ml': -14819.879827791834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c47abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_mid_sim_ps = runEvalsFigs(modelName, df_all, 4)\n",
    "print(best_setup_mid_sim_ps['d'], best_setup_mid_sim_ps['epsilon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the adjustment history\n",
    "with open('runSimulation/full72Trajectories/Model_both_x_and_y/Mid+Sim_ps/adjustment_results.pkl', 'rb') as file:\n",
    "    adjustment_his = pickle.load(file)\n",
    "\n",
    "for condition in adjustment_his['adjustment_histories']:\n",
    "    print(condition['sol_history'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb65e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_mid_sim_ps['best_y'] # barely adjusted (midline without adjustment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db51adb",
   "metadata": {},
   "source": [
    "# Mid + Sim_ps_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'Mid+Sim_ps_max'\n",
    "# max_adjustments = [np.infty]\n",
    "max_adjustments = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "epsilon_values = [10, 20, 40, 80, 100, 150, 200]\n",
    "\n",
    "# Initialize your x_init and y_init based on your specific needs\n",
    "x_init = [[nearest_value_in_range(canvasWidth/2, x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(canvasHeight/2, 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "\n",
    "# Run the function\n",
    "# Results will be the same across different anchors, so can just run one anchor\n",
    "best_setup_mid_sim_ps_max = find_best_parameters(df_all, positions, [1], ball_Xs, x_blue_range, exitPoints_single,\n",
    "                                  d_values, epsilon_values, max_adjustments, x_init, y_init, 'Mid', 'pathSim', False)\n",
    "\n",
    "# Store the results\n",
    "storeBestParams(best_setup_mid_sim_ps_max, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84acf24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_mid_sim_ps_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a950cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_mid_sim_ps_max = runEvalsFigs('Mid+Sim_ps_max', df_all, 5)\n",
    "print(best_setup_mid_sim_ps_max['d'], best_setup_mid_sim_ps_max['epsilon'], best_setup_mid_sim_ps_max['maxSteps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_setup_mid_sim_ps_max['best_x'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test visualization\n",
    "modelName = 'Mid+Sim_ps_max'\n",
    "x_init = [[nearest_value_in_range(canvasWidth/2, x_blue_range[(stimulus_idx,obstacle_idx)][0],x_blue_range[(stimulus_idx,obstacle_idx)][1]) for obstacle_idx in anchors] for stimulus_idx in positions] #(1,1)(1,2)(1,3)...(1,6)(2,1)\n",
    "y_init = [[nearest_value_in_range(canvasHeight/2, 150 + margin, 450 - margin) for obstacle_idx in anchors] for stimulus_idx in positions]\n",
    "\n",
    "simulation_scenario_test = SimulationScenario(\n",
    "                            df_all, 2, 1, x_init, y_init,\n",
    "                            ball_Xs, exitPoints_single, 'Mid', 'pathSim', 3)\n",
    "result = simulation_scenario_test.adjust_obstacle(5, 10)\n",
    "simulation_scenario_test.visualize_adjustment_process(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f3ec78",
   "metadata": {},
   "source": [
    "## Visualizations with adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7121f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, Normalize\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "\n",
    "# new function with legend\n",
    "def visualize72Trials(jsonFilePath, df_all, modelName, withAdjust = False, best_setup = None):\n",
    "    # Load JSON data, containing simulated trajectories from model prediction\n",
    "    with open(jsonFilePath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Convert data to DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "\n",
    "    # Create a 12x6 grid of plots with shared axes and constrained layout\n",
    "    fig, axes = plt.subplots(nrows=12, ncols=6, figsize=(30, 40), sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "    # Loop through each row in the dataframe\n",
    "    for idx, row in df.iterrows():\n",
    "        stimulus_idx = row['stimulus_idx'] - 1  # 0-based index for matplotlib\n",
    "        obstacle_idx = row['obstacle_idx'] - 1  # 0-based index\n",
    "\n",
    "        ax = axes[stimulus_idx, obstacle_idx]\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "        if 'LP' in modelName:\n",
    "            intersection = drawProjectedPath(row['stimulus_idx'], df_all, ax, 7)\n",
    "        \n",
    "        subset = drawInitialSetUp(ax, df_all, row['stimulus_idx'], row['obstacle_idx'])\n",
    "        \n",
    "        if withAdjust:\n",
    "            # Find history for this specific condition\n",
    "            history_idx = (row['stimulus_idx'] - 1) * 6 + (row['obstacle_idx'] - 1)\n",
    "            history = best_setup['adjustment_histories'][history_idx]\n",
    "            \n",
    "            # Human Average FD\n",
    "            human_fd = subset['fd_combined'].mean()\n",
    "#             print(human_fd)\n",
    "            \n",
    "            fd_history = history['fd_history']\n",
    "            \n",
    "            # add before/after adjustment\n",
    "            initial_x, initial_y = history['sol_history'][0][0],history['sol_history'][0][1]\n",
    "            final_x, final_y = best_setup['best_x'][history_idx],best_setup['best_y'][history_idx]\n",
    "            ax.text(0.95, 0.95, f'Initial: ({initial_x:.1f}, {initial_y:.1f})\\nFinal: ({final_x:.1f}, {final_y:.1f})',\n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            transform=ax.transAxes, color='dimgray', fontsize=8)\n",
    "        \n",
    "            # Calculate normalized differences and map to colors with controlled scaling\n",
    "            fd_differences = np.abs(np.array(fd_history) - human_fd)\n",
    "            if (fd_differences.max() - fd_differences.min()) != 0:\n",
    "                normalized_differences = (fd_differences - fd_differences.min()) / (fd_differences.max() - fd_differences.min())\n",
    "            else:\n",
    "                # If all values are the same, set them to the middle of the scale (0.5 is arbitrary and can be adjusted)\n",
    "                normalized_differences = np.full_like(fd_differences, fill_value=0.5)\n",
    "#             normalized_differences = fd_differences / 100\n",
    "    \n",
    "#             print(row['stimulus_idx'], row['obstacle_idx'])\n",
    "#             print(normalized_differences)\n",
    "            # Define lower and upper bounds for the color scaling\n",
    "            lower_bound = 0\n",
    "            upper_bound = 0.6\n",
    "            scaled_differences = lower_bound + (upper_bound - lower_bound) * normalized_differences\n",
    "        \n",
    "            colors = [plt.cm.YlOrBr(1 - diff) for diff in scaled_differences]  # The darker the color, the closer to fd_human_avg\n",
    "            \n",
    "            # Check if row['obstacle_X'] == best_setup['best_x'][history_idx]\n",
    "            error = 0.00001\n",
    "            if (abs(row['obstacle_X']-best_setup['best_x'][history_idx]) >= error) or (abs(row['obstacle_Y']-best_setup['best_y'][history_idx]) >= error):\n",
    "#                 print(row['obstacle_X'], best_setup['best_x'][history_idx])\n",
    "#                 print(row['obstacle_Y'], best_setup['best_y'][history_idx])\n",
    "                raise Exception('Unmatched Data. Check history_index with df_all.')\n",
    "                \n",
    "            obstacle = patches.RegularPolygon((row['obstacle_X'], row['obstacle_Y']), numVertices=3, radius=45, orientation=np.pi, color=colors[-1], fill=True, alpha=0.7)\n",
    "            ax.add_patch(obstacle)\n",
    "            \n",
    "            # Plot adjustment histories\n",
    "            for i, step in enumerate(history['simulated_path_history']):\n",
    "                step = np.array(step)\n",
    "#                 alpha = i/len(history['simulated_path_history'])\n",
    "                alpha = 1\n",
    "                ax.plot(step[:, 0], step[:, 1], '-', alpha=alpha, zorder=7, color=colors[i], linewidth=1)  # Change color and alpha as needed\n",
    "                \n",
    "        else:\n",
    "            # Add the model predicted obstacle position\n",
    "            obstacle = patches.RegularPolygon((row['obstacle_X'], row['obstacle_Y']), numVertices=3, radius=45, orientation=np.pi, color=model_prediction_color, fill=True, alpha=0.7)\n",
    "            ax.add_patch(obstacle)\n",
    "\n",
    "            # Plot trajectory\n",
    "            x_coords = [point[0] for point in row['simulated_trial']]\n",
    "            y_coords = [point[1] for point in row['simulated_trial']]\n",
    "            ax.plot(x_coords, y_coords, '-', linewidth=1.5, color='darkblue', label='Trajectory', zorder=6)\n",
    "\n",
    "        ax.set_xlim(100, 900)\n",
    "        ax.set_ylim(60, 540)\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_title(f'Stimulus {row[\"stimulus_idx\"]}, Obstacle {row[\"obstacle_idx\"]}')\n",
    "\n",
    "    # Add a single global legend\n",
    "    handles = [\n",
    "        patches.Patch(color=ground_truth_color, label='Ground Truth'),\n",
    "        patches.Patch(color=human_centroid_color, label='Human Centroid'),\n",
    "        patches.Patch(color=participant_color, label='Participant Trajectories'),\n",
    "        patches.Patch(color=anchor_color, label='Anchor Position')\n",
    "    ]\n",
    "    if withAdjust:\n",
    "        handles.append(patches.Patch(color=plt.cm.YlOrBr(0.5), label='Model Prediction'))\n",
    "    else:\n",
    "        handles.append(patches.Patch(color=model_prediction_color, label='Model Prediction'))\n",
    "        \n",
    "    leg = fig.legend(handles=handles, loc='upper center', bbox_to_anchor=(0.5, 1.02), ncol=5, fontsize='16')\n",
    "    \n",
    "    fig.supxlabel('X Coordinate', fontsize=16)\n",
    "    fig.supylabel('Y Coordinate', fontsize=16)\n",
    "    plt.savefig(f'{modelName}_72Trials.pdf', bbox_inches='tight', bbox_extra_artists=(leg,))\n",
    "    plt.show()\n",
    "\n",
    "# This code assumes you have the jsonFilePath and df_all prepared\n",
    "# visualize72Trials('path_to_your_data.json', df_all_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe4a9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "runEvalsFigs('Mid+Sim_ps_max', df_all, 5, True, best_setup_mid_sim_ps_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc84ee3",
   "metadata": {},
   "source": [
    "## Baseline FD comparison human vs. human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Assuming df_all contains a column 'fd_combined' with each participant's data\n",
    "correlations = []\n",
    "\n",
    "# Repeat the process 30 times\n",
    "for _ in range(30):\n",
    "    group_correlations = []\n",
    "    group_stds = []\n",
    "    \n",
    "    # Group by 'stimulus_idx' and 'obstacle_idx'\n",
    "    grouped = df_all.groupby(['stimulus_idx', 'obstacle_idx'])\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        # Shuffle and split the group into two halves\n",
    "        shuffled_group = group.sample(frac=1, random_state=np.random.randint(0, 10000))\n",
    "\n",
    "        # print(shuffled_group)\n",
    "        half_size = len(shuffled_group) // 2\n",
    "        # print(half_size)\n",
    "        \n",
    "        # Split into two halves\n",
    "        first_half = shuffled_group.iloc[:half_size]['fd_combined']\n",
    "        # print(shuffled_group.iloc[:half_size]['stimulus_idx'])\n",
    "        # print(shuffled_group.iloc[:half_size]['obstacle_idx'])\n",
    "        # print(shuffled_group.iloc[:half_size]['fd2_exit'])\n",
    "        second_half = shuffled_group.iloc[half_size:]['fd_combined']\n",
    "        \n",
    "        # Calculate the mean for each half\n",
    "        mean_first_half = first_half.mean()\n",
    "        mean_second_half = second_half.mean()\n",
    "        std_first_half = first_half.std()\n",
    "        std_second_half = second_half.std()\n",
    "        \n",
    "        # Store the mean values as an (x, y) pair\n",
    "        group_correlations.append((mean_first_half, mean_second_half))\n",
    "        group_stds.append((std_first_half, std_second_half))\n",
    "    \n",
    "    # Now calculate the correlation across all (x, y) pairs\n",
    "    if group_correlations:  # Ensure there are valid (x, y) pairs\n",
    "        first_half_vals, second_half_vals = zip(*group_correlations)\n",
    "        first_half_vals_std, second_half_vals_std = zip(*group_stds)\n",
    "\n",
    "\n",
    "        correlation = plotComparison_fd(first_half_vals, second_half_vals, first_half_vals_std, 'Human_50', second_half_vals_std)\n",
    "        correlations.append(correlation)\n",
    "\n",
    "# Convert correlations list to a DataFrame or display directly\n",
    "correlations_df = pd.DataFrame(correlations, columns=['Correlation'])\n",
    "print(correlations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Data for models and corresponding BIC values\n",
    "models = [\n",
    "    \"Uni Prior\", \"LP\", \"Anchor\", \"Midline\",\n",
    "    \"LP+Exit Point\", \"Anchor+Exit Point\", \"Midline+Exit Point\",\n",
    "    \"LP+Path Sim\", \"Anchor+Path Sim\", \"Midline+Path Sim\"\n",
    "]\n",
    "\n",
    "bic_values = [\n",
    "    31531.85, 32375.67, 31126.21, 30212.39,\n",
    "    31664.11, 30084.29, 29621.91,\n",
    "    30734.55, 29960.12, 29664.86\n",
    "]\n",
    "\n",
    "# Define color palette\n",
    "palette = sns.color_palette(\"Set2\", 4)  # 4 colors for diversity\n",
    "colors = [\n",
    "    'black', palette[0], palette[1], palette[2],  # No Adjustment models\n",
    "    palette[0], palette[1], palette[2],              # Exit Point models\n",
    "    palette[0], palette[1], palette[2]               # Path Sim models\n",
    "]\n",
    "\n",
    "# Define textures for different stopping criteria\n",
    "textures = [\n",
    "    '', '', '', '',       # No texture for no-adjustment models\n",
    "    '//', '//', '//',        # '-' texture for Exit Point models\n",
    "    '+', '+', '+'      # '\\' texture for Path Sim models\n",
    "]\n",
    "\n",
    "# Assign edge colors to match fill colors\n",
    "edge_colors = colors.copy()\n",
    "\n",
    "# Define fill colors: white for no-adjustment models, colored for adjusted models\n",
    "fill_colors = [\n",
    "    'white' if '+' not in model else colors[i] \n",
    "    for i, model in enumerate(models)\n",
    "]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "# Plot each bar with corresponding properties\n",
    "for i in range(len(models)):\n",
    "    ax.bar(\n",
    "        i, \n",
    "        bic_values[i], \n",
    "        color=fill_colors[i], \n",
    "        edgecolor=edge_colors[i], \n",
    "        hatch=textures[i], \n",
    "        alpha=0.7, \n",
    "        linewidth=2\n",
    "    )\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('BIC Values', fontsize=16)\n",
    "# ax.set_title('BIC Values by Model', fontsize=16)\n",
    "ax.set_xticks(np.arange(len(models)))\n",
    "ax.set_xticklabels(models, rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "# Adjust y-axis limits for better visibility\n",
    "y_min = min(bic_values) * 0.98\n",
    "y_max = max(bic_values) * 1.02\n",
    "ax.set_ylim(y_min, y_max)\n",
    "\n",
    "# Create custom legend\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor='white', edgecolor='black', label='UniPrior Init'),\n",
    "    Patch(facecolor=palette[0], edgecolor=palette[0], label='LP Init'),\n",
    "    Patch(facecolor=palette[1], edgecolor=palette[1], label='Anchor Init'),\n",
    "    Patch(facecolor=palette[2], edgecolor=palette[2], label='Midline Init'),\n",
    "    Patch(facecolor='lightgrey', edgecolor='black', hatch='//', label='Exit Point'),\n",
    "    Patch(facecolor='lightgrey', edgecolor='black', hatch='+', label='Path Sim')\n",
    "]\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
    "\n",
    "# Enhance layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "\n",
    "plt.savefig(\"bic_values_by_model.png\",dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b8c90",
   "metadata": {},
   "source": [
    "# updating values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Data for models and corresponding BIC values\n",
    "models = [\n",
    "    \"Uni Prior\", \"LP\", \"Anchor\", \"Midline\",\n",
    "    \"LP+Exit Point\", \"Anchor+Exit Point\", \"Midline+Exit Point\",\n",
    "    \"LP+Path Sim\", \"Anchor+Path Sim\", \"Midline+Path Sim\"\n",
    "]\n",
    "\n",
    "bic_values = [\n",
    "    31220.49, 32375.67, 31126.21, 30212.39,\n",
    "    31642.99, 30119.87, 29635.80,\n",
    "    30993.19, 29877.71, 29662.83\n",
    "]\n",
    "\n",
    "# Define color palette\n",
    "palette = sns.color_palette(\"Set2\", 4)  # 4 colors for diversity\n",
    "colors = [\n",
    "    'black', palette[0], palette[1], palette[2],  # No Adjustment models\n",
    "    palette[0], palette[1], palette[2],              # Exit Point models\n",
    "    palette[0], palette[1], palette[2]               # Path Sim models\n",
    "]\n",
    "\n",
    "# Define textures for different stopping criteria\n",
    "textures = [\n",
    "    '', '', '', '',       # No texture for no-adjustment models\n",
    "    '//', '//', '//',        # '-' texture for Exit Point models\n",
    "    '+', '+', '+'      # '\\' texture for Path Sim models\n",
    "]\n",
    "\n",
    "# Assign edge colors to match fill colors\n",
    "edge_colors = colors.copy()\n",
    "\n",
    "# Define fill colors: white for no-adjustment models, colored for adjusted models\n",
    "fill_colors = [\n",
    "    'white' if '+' not in model else colors[i] \n",
    "    for i, model in enumerate(models)\n",
    "]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "# Plot each bar with corresponding properties\n",
    "for i in range(len(models)):\n",
    "    ax.bar(\n",
    "        i, \n",
    "        bic_values[i], \n",
    "        color=fill_colors[i], \n",
    "        edgecolor=edge_colors[i], \n",
    "        hatch=textures[i], \n",
    "        alpha=0.7, \n",
    "        linewidth=2\n",
    "    )\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('BIC Values', fontsize=16)\n",
    "# ax.set_title('BIC Values by Model', fontsize=16)\n",
    "ax.set_xticks(np.arange(len(models)))\n",
    "ax.set_xticklabels(models, rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "# Adjust y-axis limits for better visibility\n",
    "y_min = min(bic_values) * 0.98\n",
    "y_max = max(bic_values) * 1.02\n",
    "ax.set_ylim(y_min, y_max)\n",
    "\n",
    "# Create custom legend\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor='white', edgecolor='black', label='UniPrior Init'),\n",
    "    Patch(facecolor=palette[0], edgecolor=palette[0], label='LP Init'),\n",
    "    Patch(facecolor=palette[1], edgecolor=palette[1], label='Anchor Init'),\n",
    "    Patch(facecolor=palette[2], edgecolor=palette[2], label='Midline Init'),\n",
    "    Patch(facecolor='lightgrey', edgecolor='black', hatch='//', label='Exit Point'),\n",
    "    Patch(facecolor='lightgrey', edgecolor='black', hatch='+', label='Path Sim')\n",
    "]\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
    "\n",
    "# Enhance layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "\n",
    "plt.savefig(\"bic_values_by_model.png\",dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadf710f",
   "metadata": {},
   "source": [
    "# Update Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Data for models and corresponding r values\n",
    "models = [\n",
    "    \"Uni Prior\", \"LP\", \"Anchor\", \"Midline\",\n",
    "    \"LP+Exit Point\", \"Anchor+Exit Point\", \"Midline+Exit Point\",\n",
    "    \"LP+Path Sim\", \"Anchor+Path Sim\", \"Midline+Path Sim\"\n",
    "]\n",
    "\n",
    "r_values = [\n",
    "    0.282, 0.466, 0.534, 0.437,\n",
    "    0.488, 0.171, 0.383,\n",
    "    0.389, 0.147, 0.109\n",
    "]\n",
    "\n",
    "# Define color palette\n",
    "palette = sns.color_palette(\"Set2\", 4)  # 4 colors for diversity\n",
    "colors = [\n",
    "    'black', palette[0], palette[1], palette[2],  # No Adjustment models\n",
    "    palette[0], palette[1], palette[2],              # Exit Point models\n",
    "    palette[0], palette[1], palette[2]               # Path Sim models\n",
    "]\n",
    "\n",
    "# Define textures for different stopping criteria\n",
    "textures = [\n",
    "    '', '', '', '',       # No texture for no-adjustment models\n",
    "    '//', '//', '//',        # '-' texture for Exit Point models\n",
    "    '+', '+', '+'      # '\\' texture for Path Sim models\n",
    "]\n",
    "\n",
    "# Assign edge colors to match fill colors\n",
    "edge_colors = colors.copy()\n",
    "\n",
    "# Define fill colors: white for no-adjustment models, colored for adjusted models\n",
    "fill_colors = [\n",
    "    'white' if '+' not in model else colors[i] \n",
    "    for i, model in enumerate(models)\n",
    "]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "# Plot each bar with corresponding properties\n",
    "for i in range(len(models)):\n",
    "    ax.bar(\n",
    "        i, \n",
    "        r_values[i], \n",
    "        color=fill_colors[i], \n",
    "        edgecolor=edge_colors[i], \n",
    "        hatch=textures[i], \n",
    "        alpha=0.7, \n",
    "        linewidth=2\n",
    "    )\n",
    "\n",
    "# Add the horizontal line at the average human correlation\n",
    "average_correlation = 0.28325\n",
    "ax.axhline(y=average_correlation, color='darkgray', linestyle='--', linewidth=2, label=f'Avg Human Corr = {average_correlation:.3f}')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('Correlation (r)', fontsize=16)\n",
    "ax.set_xticks(np.arange(len(models)))\n",
    "ax.set_xticklabels(models, rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "# Adjust y-axis limits for better visibility\n",
    "y_min = min(r_values) * 0.95\n",
    "y_max = max(r_values) * 1.05\n",
    "ax.set_ylim(y_min, y_max)\n",
    "\n",
    "# Create custom legend\n",
    "legend_elements = [\n",
    "    Patch(facecolor='white', edgecolor='black', label='UniPrior Init'),\n",
    "    Patch(facecolor=palette[0], edgecolor=palette[0], label='LP Init'),\n",
    "    Patch(facecolor=palette[1], edgecolor=palette[1], label='Anchor Init'),\n",
    "    Patch(facecolor=palette[2], edgecolor=palette[2], label='Midline Init'),\n",
    "    Patch(facecolor='lightgrey', edgecolor='black', hatch='//', label='Exit Point'),\n",
    "    Patch(facecolor='lightgrey', edgecolor='black', hatch='+', label='Path Sim'),\n",
    "    plt.Line2D([0], [1], color='darkgray', linestyle='--', linewidth=2, label=f'Avg Human Corr')\n",
    "]\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
    "\n",
    "# Enhance layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"correlation_values_by_model.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to include everything in the graph (not recommended)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Data for models and corresponding BIC values (added capped and non-capped variants)\n",
    "models = [\n",
    "    \"Uni Prior\", \"LP\", \"Anchor\", \"Midline\",\n",
    "    \"LP+Exit Point\", \"Anchor+Exit Point\", \"Midline+Exit Point\",\n",
    "    \"LP+Exit Point (Cap)\", \"Anchor+Exit Point (Cap)\", \"Midline+Exit Point (Cap)\",\n",
    "    \"LP+Path Sim\", \"Anchor+Path Sim\", \"Midline+Path Sim\",\n",
    "    \"LP+Path Sim (Cap)\", \"Anchor+Path Sim (Cap)\", \"Midline+Path Sim (Cap)\"\n",
    "]\n",
    "\n",
    "# Updated BIC values with capped versions\n",
    "bic_values = [\n",
    "    31220.49, 32375.67, 31126.21, 30212.39,           # No Adjustment\n",
    "    31635.71, 30116.73, 29637.68,                     # Exit Point\n",
    "    31642.99, 30119.87, 29635.80,                     # Exit Point (Capped)\n",
    "    31117.88, 29891.78, 29668.85,                     # Path Sim\n",
    "    30993.19, 29877.71, 29662.83                      # Path Sim (Capped)\n",
    "]\n",
    "\n",
    "# Define color palette\n",
    "palette = sns.color_palette(\"Set2\", 4)  # 4 colors for diversity\n",
    "colors = [\n",
    "    'black', palette[0], palette[1], palette[2],  # No Adjustment models\n",
    "    palette[0], palette[1], palette[2],           # Exit Point models\n",
    "    palette[0], palette[1], palette[2],           # Exit Point (Capped)\n",
    "    palette[0], palette[1], palette[2],           # Path Sim models\n",
    "    palette[0], palette[1], palette[2]            # Path Sim (Capped)\n",
    "]\n",
    "\n",
    "# Define textures for different stopping criteria and fill colors for capped/non-capped\n",
    "textures = [\n",
    "    '', '', '', '',                               # No texture for no-adjustment models\n",
    "    '//', '//', '//',                             # Exit Point models\n",
    "    '', '', '',                                   # Exit Point (Capped): no texture\n",
    "    '+', '+', '+',                                # Path Sim models\n",
    "    '', '', ''                                    # Path Sim (Capped): no texture\n",
    "]\n",
    "\n",
    "# Assign edge colors to match fill colors for non-capped, and use light grey for capped\n",
    "fill_colors = [\n",
    "    'white' if '+' not in model else colors[i]    # White for no-adjustment models\n",
    "    for i, model in enumerate(models)\n",
    "]\n",
    "\n",
    "# For capped models, make fill color white to differentiate\n",
    "for i, model in enumerate(models):\n",
    "    if 'Cap' in model:\n",
    "        fill_colors[i] = 'white'  # No fill color for capped models\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot each bar with corresponding properties\n",
    "for i in range(len(models)):\n",
    "    ax.bar(\n",
    "        i, \n",
    "        bic_values[i], \n",
    "        color=fill_colors[i], \n",
    "        edgecolor=colors[i], \n",
    "        hatch=textures[i], \n",
    "        alpha=0.7, \n",
    "        linewidth=2\n",
    "    )\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('BIC Values', fontsize=16)\n",
    "ax.set_xticks(np.arange(len(models)))\n",
    "ax.set_xticklabels(models, rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "# Adjust y-axis limits for better visibility\n",
    "y_min = min(bic_values) * 0.98\n",
    "y_max = max(bic_values) * 1.02\n",
    "ax.set_ylim(y_min, y_max)\n",
    "\n",
    "# Create custom legend\n",
    "legend_elements = [\n",
    "    Patch(facecolor='white', edgecolor='black', label='UniPrior Init'),\n",
    "    Patch(facecolor=palette[0], edgecolor=palette[0], label='LP Init'),\n",
    "    Patch(facecolor=palette[1], edgecolor=palette[1], label='Anchor Init'),\n",
    "    Patch(facecolor=palette[2], edgecolor=palette[2], label='Midline Init'),\n",
    "    Patch(facecolor='lightgrey', edgecolor='black', hatch='//', label='Exit Point'),\n",
    "    Patch(facecolor='lightgrey', edgecolor='black', hatch='+', label='Path Sim'),\n",
    "    Patch(facecolor='white', edgecolor='lightgrey', label='Capped Max Steps')  # Legend for capped models\n",
    "]\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
    "\n",
    "# Enhance layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig(\"bic_values_by_model.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Data for models with adjustments only\n",
    "models = [\n",
    "    \"LP+Exit Point\", \"LP+Exit Point (Max)\", \n",
    "    \"Anchor+Exit Point\", \"Anchor+Exit Point (Max)\", \n",
    "    \"Midline+Exit Point\", \"Midline+Exit Point (Max)\", \n",
    "    \"LP+Path Sim\", \"LP+Path Sim (Max)\", \n",
    "    \"Anchor+Path Sim\", \"Anchor+Path Sim (Max)\", \n",
    "    \"Midline+Path Sim\", \"Midline+Path Sim (Max)\"\n",
    "]\n",
    "\n",
    "# BIC values for models with adjustments only\n",
    "bic_values = [\n",
    "    31635.71, 31642.99, \n",
    "    30116.73, 30119.87, \n",
    "    29637.68, 29635.80, \n",
    "    31117.88, 30993.19, \n",
    "    29891.78, 29877.71, \n",
    "    29668.85, 29662.83\n",
    "]\n",
    "\n",
    "# Define color palette\n",
    "palette = sns.color_palette(\"Set2\", 3)  # 3 colors for LP, Anchor, Midline\n",
    "colors = [\n",
    "    palette[0], palette[0],       # LP+Exit Point and LP+Exit Point (Max)\n",
    "    palette[1], palette[1],       # Anchor+Exit Point and Anchor+Exit Point (Max)\n",
    "    palette[2], palette[2],       # Midline+Exit Point and Midline+Exit Point (Max)\n",
    "    palette[0], palette[0],       # LP+Path Sim and LP+Path Sim (Max)\n",
    "    palette[1], palette[1],       # Anchor+Path Sim and Anchor+Path Sim (Max)\n",
    "    palette[2], palette[2]        # Midline+Path Sim and Midline+Path Sim (Max)\n",
    "]\n",
    "\n",
    "# Use darker for non-Max and lighter for Max, with a texture for Max\n",
    "fill_colors = [\n",
    "    colors[i] if \"Max\" in models[i] else 'white'  # No fill color for Max models\n",
    "    for i in range(len(models))\n",
    "]\n",
    "\n",
    "# Define hatch patterns for Max models\n",
    "hatch_patterns = [\n",
    "    '//', '//',   # LP+Exit Point\n",
    "    '//', '//',   # Anchor+Exit Point\n",
    "    '//', '//',   # Midline+Exit Point\n",
    "    '+', '+',   # LP+Path Sim\n",
    "    '+', '+',   # Anchor+Path Sim\n",
    "    '+', '+'    # Midline+Path Sim\n",
    "]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "# Plot each bar with corresponding properties\n",
    "bar_width = 0.8  # Narrower bars to group non-max and max together\n",
    "for i in range(0, len(models), 2):\n",
    "    # Plot non-Max\n",
    "    ax.bar(\n",
    "        i, \n",
    "        bic_values[i], \n",
    "        color=fill_colors[i], \n",
    "        edgecolor=colors[i], \n",
    "        hatch=hatch_patterns[i], \n",
    "        alpha=0.7, \n",
    "        linewidth=2, \n",
    "        width=bar_width\n",
    "    )\n",
    "    # Plot Max next to non-Max\n",
    "    ax.bar(\n",
    "        i + 1, \n",
    "        bic_values[i + 1], \n",
    "        color=fill_colors[i + 1], \n",
    "        edgecolor=colors[i + 1], \n",
    "        hatch=hatch_patterns[i + 1], \n",
    "        alpha=0.7, \n",
    "        linewidth=2, \n",
    "        width=bar_width\n",
    "    )\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('BIC Values', fontsize=16)\n",
    "ax.set_xticks(np.arange(0, len(models), 2) + bar_width / 2)\n",
    "ax.set_xticklabels([models[i] for i in range(0, len(models), 2)], rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "# Adjust y-axis limits for better visibility\n",
    "y_min = min(bic_values) * 0.98\n",
    "y_max = max(bic_values) * 1.02\n",
    "ax.set_ylim(y_min, y_max)\n",
    "\n",
    "# Create custom legend for non-max and max models\n",
    "legend_elements = [\n",
    "    Patch(facecolor=palette[0], edgecolor=palette[0], label='LP Init'),\n",
    "    Patch(facecolor=palette[1], edgecolor=palette[1], label='Anchor Init'),\n",
    "    Patch(facecolor=palette[2], edgecolor=palette[2], label='Midline Init'),\n",
    "    Patch(facecolor='lightgrey', edgecolor='black', hatch='//', label='Exit Point'),\n",
    "    Patch(facecolor='lightgrey', edgecolor='black', hatch='+', label='Path Sim'),\n",
    "    Patch(facecolor='white', edgecolor='lightgrey', label='No Max Steps Limit') \n",
    "]\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
    "\n",
    "# Enhance layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig(\"bic_values_adjusted_models.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde75796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
